{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import seaborn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock(tickr):\n",
    "    start = pd.to_datetime('2010-08-02')\n",
    "    end = pd.to_datetime('2018-08-02')\n",
    "    stock = [tickr]\n",
    "    data = yf.download(stock, start = start, end = end)\n",
    "    data.reset_index(inplace = True)\n",
    "    data = data[['Open', 'High','Low', 'Close']]\n",
    "\n",
    "    y = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(data) - 1):\n",
    "        if data.loc[i + 1, 'Open'] - data.loc[i, 'Close'] > 0:\n",
    "            y.loc[i, 0] = 1\n",
    "        else:\n",
    "            y.loc[i, 0] = 0\n",
    "\n",
    "    data_train = data.iloc[0:1601,] \n",
    "    data_test = data.iloc[1601:2001,]\n",
    "\n",
    "    y_train = y.iloc[0:1601,] \n",
    "    y_test = y.iloc[1601:2001,]\n",
    "\n",
    "    return data_train, data_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_exp(data):\n",
    "    # use the estimates to calculate the curve\n",
    "    preprocessed = pd.DataFrame()\n",
    "    PF = pd.DataFrame()\n",
    "    \n",
    "    for col in ['Open', 'High', 'Low', 'Close']:\n",
    "        PF = np.polyfit(data.index, np.log(data.loc[:, col]), 1)\n",
    "        # divide by trend\n",
    "        str_col = col + 'NoExp'\n",
    "        preprocessed[str_col] = data[col] / (np.exp(PF[0] * data.index + PF[1]))\n",
    "        preprocessed[str_col] = (preprocessed[str_col] - np.mean(preprocessed[str_col]))/np.std(preprocessed[str_col])\n",
    "\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fixed-window sequences for training and validation data\n",
    "def create_sequences(X, y, window_size):\n",
    "    seq_X = []\n",
    "    seq_y = []\n",
    "    for i in range(len(X) - window_size):\n",
    "        seq_X.append(X.iloc[i:i+window_size,])\n",
    "        seq_y.append(y.iloc[i+window_size,])\n",
    "    return np.array(seq_X), np.array(seq_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(x_train, y_train, x_validation, y_validation, window_size, options):\n",
    "    # Build the FFNN model\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(window_size, 4))) \n",
    "    model.add(keras.layers.Dense(options[0][0], activation='relu'))\n",
    "\n",
    "    if len(options[0]) > 1:\n",
    "        if len(options[0]) > 2:\n",
    "            for i in range(1,len(options[0])-1):\n",
    "                model.add(keras.layers.Dense(options[0][i], activation=options[1]))\n",
    "                \n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train, epochs=options[3], batch_size=options[2], validation_data=(x_validation, y_validation), verbose = 0)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(x_validation)\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(x_validation, y_validation)\n",
    "\n",
    "    return accuracy, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, x_validation, y_validation):\n",
    "    predictValidation = model.predict(x_validation)\n",
    "\n",
    "    modelResults = pd.DataFrame()\n",
    "    modelResults[\"realValues\"] = pd.DataFrame(y_validation)\n",
    "    modelResults[\"estimatedValues\"] = pd.DataFrame(predictValidation)\n",
    "\n",
    "    for i in range(len(modelResults)):\n",
    "        if modelResults.loc[i, \"estimatedValues\"] > 0.5:\n",
    "            modelResults.loc[i, \"estimatedValues\"] = 1\n",
    "        else:\n",
    "            modelResults.loc[i, \"estimatedValues\"] = 0\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cf = confusion_matrix(np.array(modelResults[\"realValues\"]), np.array(modelResults[\"estimatedValues\"]))\n",
    "\n",
    "    print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "tickers = ['GOOG','AAPL','MSFT','AMZN','NVDA']\n",
    "window_size = 5\n",
    "\n",
    "x_train_total = []\n",
    "y_train_total = []\n",
    "\n",
    "x_validation_total = []\n",
    "y_validation_total = []\n",
    "\n",
    "for tickr in tickers:\n",
    "    data_train, data_test, y_train, y_test = get_stock(tickr)\n",
    "    preprocessed = preprocess_exp(data_train)\n",
    "    x_train_seq, y_train_seq = create_sequences(preprocessed.iloc[0:1301,], y_train.iloc[:1301,], window_size)\n",
    "    x_validation_seq, y_validation_seq = create_sequences(preprocessed.iloc[1301:,], y_train.iloc[1301:1601,], window_size)\n",
    "\n",
    "    x_train_total.append(x_train_seq)\n",
    "    y_train_total.append(y_train_seq)\n",
    "\n",
    "    x_validation_total.append(x_validation_seq)\n",
    "    y_validation_total.append(y_validation_seq)\n",
    "\n",
    "x_train_total = np.array(x_train_total).reshape((len(tickers)*(1301-window_size)),window_size,4)\n",
    "y_train_total = np.array(y_train_total).reshape((len(tickers)*(1301-window_size)),1)\n",
    "\n",
    "x_validation_total = np.array(x_validation_total).reshape((len(tickers)*(1601-1301-window_size)),window_size,4)\n",
    "y_validation_total = np.array(y_validation_total).reshape((len(tickers)*(1601-1301-window_size)),1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before undersampling:\n",
      "1.0    3458\n",
      "0.0    3022\n",
      "dtype: int64\n",
      "Class distribution after undersampling:\n",
      "0.0    3022\n",
      "1.0    3022\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the class distribution before and after undersampling\n",
    "print(\"Class distribution before undersampling:\")\n",
    "print(pd.Series(y_train_total.flatten()).value_counts())\n",
    "\n",
    "zeros = pd.Series(y_train_total.flatten()).value_counts()[0]\n",
    "ones = pd.Series(y_train_total.flatten()).value_counts()[1]\n",
    "\n",
    "indexes = np.array(np.where(y_train_total == 1)[0])\n",
    "\n",
    "random_numbers = np.random.choice(indexes, size=ones-zeros, replace=False)\n",
    "\n",
    "x_train_total = np.delete(x_train_total, random_numbers, axis = 0)\n",
    "y_train_total = np.delete(y_train_total, random_numbers, axis = 0)\n",
    "\n",
    "# Print the class distribution before and after undersampling\n",
    "print(\"Class distribution after undersampling:\")\n",
    "print(pd.Series(y_train_total.flatten()).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print the class distribution before and after undersampling\n",
    "# print(\"Class distribution before undersampling:\")\n",
    "# print(pd.Series(y_validation_total.flatten()).value_counts())\n",
    "\n",
    "# zeros = pd.Series(y_validation_total.flatten()).value_counts()[0]\n",
    "# ones = pd.Series(y_validation_total.flatten()).value_counts()[1]\n",
    "\n",
    "# indexes = np.array(np.where(y_validation_total == 1)[0])\n",
    "\n",
    "# random_numbers = np.random.choice(indexes, size=ones-zeros, replace=False)\n",
    "\n",
    "# x_validation_total = np.delete(x_validation_total, random_numbers, axis = 0)\n",
    "# y_validation_total = np.delete(y_validation_total, random_numbers, axis = 0)\n",
    "\n",
    "# # Print the class distribution before and after undersampling\n",
    "# print(\"Class distribution after undersampling:\")\n",
    "# print(pd.Series(y_validation_total.flatten()).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 413us/step\n",
      "47/47 [==============================] - 0s 504us/step - loss: 0.6849 - accuracy: 0.5607\n",
      "47/47 [==============================] - 0s 403us/step\n",
      "47/47 [==============================] - 0s 489us/step - loss: 0.6874 - accuracy: 0.5553\n",
      "47/47 [==============================] - 0s 408us/step\n",
      "47/47 [==============================] - 0s 560us/step - loss: 0.6920 - accuracy: 0.5444\n",
      "47/47 [==============================] - 0s 408us/step\n",
      "47/47 [==============================] - 0s 484us/step - loss: 0.6844 - accuracy: 0.5478\n",
      "47/47 [==============================] - 0s 409us/step\n",
      "47/47 [==============================] - 0s 481us/step - loss: 0.6953 - accuracy: 0.4786\n",
      "47/47 [==============================] - 0s 399us/step\n",
      "47/47 [==============================] - 0s 523us/step - loss: 0.6891 - accuracy: 0.5566\n",
      "47/47 [==============================] - 0s 409us/step\n",
      "47/47 [==============================] - 0s 479us/step - loss: 0.6913 - accuracy: 0.5220\n",
      "47/47 [==============================] - 0s 409us/step\n",
      "47/47 [==============================] - 0s 488us/step - loss: 0.6901 - accuracy: 0.5458\n",
      "47/47 [==============================] - 0s 401us/step\n",
      "47/47 [==============================] - 0s 483us/step - loss: 0.6977 - accuracy: 0.4692\n",
      "47/47 [==============================] - 0s 402us/step\n",
      "47/47 [==============================] - 0s 488us/step - loss: 0.6996 - accuracy: 0.4793\n",
      "          0        1   2   3         4\n",
      "0  [64, 64]  sigmoid  64  10  0.525966\n",
      "47/47 [==============================] - 0s 417us/step\n",
      "[[595  72]\n",
      " [696 112]]\n"
     ]
    }
   ],
   "source": [
    "lays = [[64,64]]\n",
    "epochs = [10]\n",
    "batchSizes = [64]\n",
    "activationFunctions = ['sigmoid']\n",
    "\n",
    "options = []\n",
    "\n",
    "for layer in lays:\n",
    "    for activation in activationFunctions:\n",
    "        for batchSize in batchSizes:\n",
    "            for epoch in epochs:\n",
    "                options.append([layer, activation, batchSize, epoch, 0])\n",
    "\n",
    "for i in range(len(options)):\n",
    "    ac=[]\n",
    "    for j in range(10):\n",
    "        a, model = build_model(x_train_total, y_train_total, x_validation_total, y_validation_total, window_size, options[i])\n",
    "        ac.append(a)\n",
    "    options[i][4] = np.mean(ac)\n",
    "\n",
    "\n",
    "op = pd.DataFrame(options)\n",
    "res = op.sort_values(4, ascending=False)\n",
    "print(res.head(84))\n",
    "\n",
    "get_accuracy(model, x_validation_total, y_validation_total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38918c03f5e50da0883dd5b0b10b29c968b274fb52fc312fcc1e11a6fe51f463"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
