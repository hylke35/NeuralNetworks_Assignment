{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import seaborn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock(tickr):\n",
    "    start = pd.to_datetime('2010-08-02')\n",
    "    end = pd.to_datetime('2018-08-02')\n",
    "    stock = [tickr]\n",
    "    data = yf.download(stock, start = start, end = end)\n",
    "    data.reset_index(inplace = True)\n",
    "    data = data[['Open', 'High','Low', 'Close']]\n",
    "\n",
    "    y = pd.DataFrame()\n",
    "\n",
    "    for i in range(len(data) - 1):\n",
    "        if data.loc[i + 1, 'Open'] - data.loc[i, 'Close'] > 0:\n",
    "            y.loc[i, 0] = 1\n",
    "        else:\n",
    "            y.loc[i, 0] = 0\n",
    "\n",
    "    data_train = data.iloc[0:1601,] \n",
    "    data_test = data.iloc[1601:2001,]\n",
    "\n",
    "    y_train = y.iloc[0:1601,] \n",
    "    y_test = y.iloc[1601:2001,]\n",
    "\n",
    "    return data_train, data_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_exp(data):\n",
    "    # use the estimates to calculate the curve\n",
    "    preprocessed = pd.DataFrame()\n",
    "    PF = pd.DataFrame()\n",
    "    \n",
    "    for col in ['Open', 'High', 'Low', 'Close']:\n",
    "        PF = np.polyfit(data.index, np.log(data.loc[:, col]), 1)\n",
    "        # divide by trend\n",
    "        str_col = col + 'NoExp'\n",
    "        preprocessed[str_col] = data[col] / (np.exp(PF[0] * data.index + PF[1]))\n",
    "        preprocessed[str_col] = (preprocessed[str_col] - np.mean(preprocessed[str_col]))/np.std(preprocessed[str_col])\n",
    "\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fixed-window sequences for training and validation data\n",
    "def create_sequences(X, y, window_size):\n",
    "    seq_X = []\n",
    "    seq_y = []\n",
    "    for i in range(len(X) - window_size):\n",
    "        seq_X.append(X.iloc[i:i+window_size,])\n",
    "        seq_y.append(y.iloc[i+window_size,])\n",
    "    return np.array(seq_X), np.array(seq_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(x_train, y_train, x_validation, y_validation, window_size, options):\n",
    "    # Build the FFNN model\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(window_size, 4))) \n",
    "    model.add(keras.layers.Dense(options[0][0], activation='relu'))\n",
    "\n",
    "    if len(options[0]) > 1:\n",
    "        if len(options[0]) > 2:\n",
    "            for i in range(1,len(options[0])-1):\n",
    "                model.add(keras.layers.Dense(options[0][i], activation=options[1]))\n",
    "                \n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train, epochs=options[3], batch_size=options[2], validation_data=(x_validation, y_validation), verbose = 0)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(x_validation)\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(x_validation, y_validation)\n",
    "\n",
    "    return accuracy, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, x_validation, y_validation):\n",
    "    predictValidation = model.predict(x_validation)\n",
    "\n",
    "    modelResults = pd.DataFrame()\n",
    "    modelResults[\"realValues\"] = pd.DataFrame(y_validation)\n",
    "    modelResults[\"estimatedValues\"] = pd.DataFrame(predictValidation)\n",
    "\n",
    "    for i in range(len(modelResults)):\n",
    "        if modelResults.loc[i, \"estimatedValues\"] > 0.5:\n",
    "            modelResults.loc[i, \"estimatedValues\"] = 1\n",
    "        else:\n",
    "            modelResults.loc[i, \"estimatedValues\"] = 0\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cf = confusion_matrix(np.array(modelResults[\"realValues\"]), np.array(modelResults[\"estimatedValues\"]))\n",
    "\n",
    "    print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "47/47 [==============================] - 0s 419us/step\n",
      "47/47 [==============================] - 0s 493us/step - loss: 0.6894 - accuracy: 0.5478\n",
      "47/47 [==============================] - 0s 403us/step\n",
      "47/47 [==============================] - 0s 482us/step - loss: 0.6891 - accuracy: 0.5478\n",
      "47/47 [==============================] - 0s 402us/step\n",
      "47/47 [==============================] - 0s 497us/step - loss: 0.6871 - accuracy: 0.5478\n",
      "47/47 [==============================] - 0s 399us/step\n",
      "47/47 [==============================] - 0s 483us/step - loss: 0.6895 - accuracy: 0.5478\n",
      "47/47 [==============================] - 0s 390us/step\n",
      "47/47 [==============================] - 0s 470us/step - loss: 0.6888 - accuracy: 0.5485\n",
      "47/47 [==============================] - 0s 467us/step\n",
      "47/47 [==============================] - 0s 760us/step - loss: 0.6891 - accuracy: 0.5478\n",
      "47/47 [==============================] - 0s 411us/step\n",
      "47/47 [==============================] - 0s 479us/step - loss: 0.6883 - accuracy: 0.5485\n",
      "47/47 [==============================] - 0s 419us/step\n",
      "47/47 [==============================] - 0s 481us/step - loss: 0.6893 - accuracy: 0.5451\n",
      "47/47 [==============================] - 0s 409us/step\n",
      "47/47 [==============================] - 0s 502us/step - loss: 0.6876 - accuracy: 0.5485\n",
      "47/47 [==============================] - 0s 414us/step\n",
      "47/47 [==============================] - 0s 522us/step - loss: 0.6853 - accuracy: 0.5478\n",
      "     0        1   2   3         4\n",
      "0  [1]  sigmoid  64  10  0.547729\n"
     ]
    }
   ],
   "source": [
    "tickers = ['GOOG','AAPL','MSFT','AMZN','NVDA']\n",
    "window_size = 5\n",
    "\n",
    "x_train_total = []\n",
    "y_train_total = []\n",
    "\n",
    "x_validation_total = []\n",
    "y_validation_total = []\n",
    "\n",
    "for tickr in tickers:\n",
    "    data_train, data_test, y_train, y_test = get_stock(tickr)\n",
    "    preprocessed = preprocess_exp(data_train)\n",
    "    x_train_seq, y_train_seq = create_sequences(preprocessed.iloc[0:1301,], y_train.iloc[:1301,], window_size)\n",
    "    x_validation_seq, y_validation_seq = create_sequences(preprocessed.iloc[1301:,], y_train.iloc[1301:1601,], window_size)\n",
    "\n",
    "    x_train_total.append(x_train_seq)\n",
    "    y_train_total.append(y_train_seq)\n",
    "\n",
    "    x_validation_total.append(x_validation_seq)\n",
    "    y_validation_total.append(y_validation_seq)\n",
    "\n",
    "x_train_total = np.array(x_train_total).reshape((len(tickers)*(1301-window_size)),window_size,4)\n",
    "y_train_total = np.array(y_train_total).reshape((len(tickers)*(1301-window_size)),1)\n",
    "\n",
    "x_validation_total = np.array(x_validation_total).reshape((len(tickers)*(1601-1301-window_size)),window_size,4)\n",
    "y_validation_total = np.array(y_validation_total).reshape((len(tickers)*(1601-1301-window_size)),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 0s 425us/step\n",
      "47/47 [==============================] - 0s 551us/step - loss: 0.6837 - accuracy: 0.5553\n",
      "47/47 [==============================] - 0s 419us/step\n",
      "47/47 [==============================] - 0s 538us/step - loss: 0.6908 - accuracy: 0.5376\n",
      "47/47 [==============================] - 0s 399us/step\n",
      "47/47 [==============================] - 0s 512us/step - loss: 0.6845 - accuracy: 0.5620\n",
      "47/47 [==============================] - 0s 396us/step\n",
      "47/47 [==============================] - 0s 489us/step - loss: 0.6843 - accuracy: 0.5573\n",
      "47/47 [==============================] - 0s 412us/step\n",
      "47/47 [==============================] - 0s 478us/step - loss: 0.6833 - accuracy: 0.5485\n",
      "47/47 [==============================] - 0s 413us/step\n",
      "47/47 [==============================] - 0s 496us/step - loss: 0.6868 - accuracy: 0.5525\n",
      "47/47 [==============================] - 0s 416us/step\n",
      "47/47 [==============================] - 0s 475us/step - loss: 0.6833 - accuracy: 0.5586\n",
      "47/47 [==============================] - 0s 424us/step\n",
      "47/47 [==============================] - 0s 482us/step - loss: 0.6829 - accuracy: 0.5620\n",
      "47/47 [==============================] - 0s 474us/step\n",
      "47/47 [==============================] - 0s 531us/step - loss: 0.6851 - accuracy: 0.5505\n",
      "47/47 [==============================] - 0s 429us/step\n",
      "47/47 [==============================] - 0s 484us/step - loss: 0.6813 - accuracy: 0.5688\n",
      "          0        1   2   3         4\n",
      "0  [64, 64]  sigmoid  64  10  0.555322\n",
      "47/47 [==============================] - 0s 455us/step\n",
      "[[ 91 576]\n",
      " [ 60 748]]\n"
     ]
    }
   ],
   "source": [
    "lays = [[64,64]]\n",
    "epochs = [10]\n",
    "batchSizes = [64]\n",
    "activationFunctions = ['sigmoid']\n",
    "\n",
    "options = []\n",
    "\n",
    "for layer in lays:\n",
    "    for activation in activationFunctions:\n",
    "        for batchSize in batchSizes:\n",
    "            for epoch in epochs:\n",
    "                options.append([layer, activation, batchSize, epoch, 0])\n",
    "\n",
    "for i in range(len(options)):\n",
    "    ac=[]\n",
    "    for j in range(10):\n",
    "        a, model = build_model(x_train_total, y_train_total, x_validation_total, y_validation_total, window_size, options[i])\n",
    "        ac.append(a)\n",
    "    options[i][4] = np.mean(ac)\n",
    "\n",
    "\n",
    "op = pd.DataFrame(options)\n",
    "res = op.sort_values(4, ascending=False)\n",
    "print(res.head(84))\n",
    "\n",
    "get_accuracy(model, x_validation_total, y_validation_total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38918c03f5e50da0883dd5b0b10b29c968b274fb52fc312fcc1e11a6fe51f463"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
