{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zaur72VQkZnP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "import seaborn\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from collections import namedtuple\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "SV4WTnKRk7V8",
        "outputId": "f3fd8ddc-f190-42ac-f8a5-37cbffcff798"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel(\"M3C.xls\", usecols=\"A:Z\")\n",
        "\n",
        "df_micro = df.iloc[0:146,]\n",
        "df_micro = df_micro.iloc[:,6:27]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# De-trend (each time series at a time)\n",
        "data = pd.DataFrame(df_micro.iloc[0])\n",
        "data.columns = [\"value\"]\n",
        "year = np.arange(0, 20)\n",
        "data['year'] = year\n",
        "data = data.set_index('year')\n",
        "\n",
        "# Perform seasonal decomposition\n",
        "decomposition = seasonal_decompose(data['value'], model='additive', period=10)\n",
        "\n",
        "# Access the components of the decomposition\n",
        "trend = decomposition.trend\n",
        "#seasonal = decomposition.seasonal\n",
        "#residual = decomposition.resid\n",
        "test2 = pd.DataFrame(trend).plot()\n",
        "trend\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qDPl7xrxzPaB"
      },
      "outputs": [],
      "source": [
        "df_train = df_micro.iloc[:,:-6]\n",
        "df_test = df_micro.iloc[:, -6:]\n",
        "\n",
        "# Standardising\n",
        "scaler = StandardScaler()\n",
        "df_train = scaler.fit_transform(df_train.to_numpy().reshape(-1,1))\n",
        "df_train = pd.DataFrame(df_train)\n",
        "MEAN = scaler.mean_\n",
        "STD = scaler.scale_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KPru18rPwBtN"
      },
      "outputs": [],
      "source": [
        "def get_labelled_window(x, horizon=1):\n",
        "  return x[:, :-horizon], x[:, -horizon]\n",
        "\n",
        "def make_windows(x, window_size=4, horizon=1):\n",
        "  window_step = np.expand_dims(np.arange(window_size+horizon), axis=0)\n",
        "  window_indexes = window_step + np.expand_dims(np.arange(len(x)-(window_size+horizon-1)), axis=0).T # create 2D array of windows of window size\n",
        "  windowed_array = x[window_indexes]\n",
        "  windows, labels = get_labelled_window(windowed_array, horizon=horizon)\n",
        "  return windows.reshape(-1,4), labels.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test = df_test.to_numpy().reshape(-1,1)\n",
        "df_test = pd.DataFrame(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_x, train_y = make_windows(df_train.to_numpy(), window_size=4, horizon=1)\n",
        "test2_x, test2_y = make_windows(df_test.to_numpy(), window_size=4, horizon=1)\n",
        "train_x_2 = train_x + 2\n",
        "train_x_2 = np.log(train_x_2)\n",
        "train_y_2 = train_y + 2\n",
        "train_y_2 = np.log(train_y_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1J7pKjWMmxVN"
      },
      "outputs": [],
      "source": [
        "# Create a function to implement a ModelCheckpoint callback\n",
        "def create_model_checkpoint(model_name, save_path=\"model_experiments\"):\n",
        "  return tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_path, model_name),\n",
        "                                            verbose=0,\n",
        "                                            save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SMAPE\n",
        "def evaluate_smape(y_true, y_pred):\n",
        "    return 200 * np.mean(np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true)))\n",
        "\n",
        "def evaluate_mdape(y_true, y_pred):\n",
        " return np.median((np.abs(np.subtract(y_true, y_pred)/ y_true))) * 100\n",
        "\n",
        "def calculate_average_rankings(y_true, y_pred):\n",
        "    num_series = len(y_pred)\n",
        "    num_methods = len(y_pred[0])\n",
        "\n",
        "    ranks = []  # to store ranks for each series\n",
        "\n",
        "    for series_index in range(num_series):\n",
        "        sape_values = [\n",
        "            abs((y_true[series_index] - forecast) / y_true[series_index]) * 100\n",
        "            for forecast in y_pred[series_index]\n",
        "        ]\n",
        "        sorted_sape = sorted(sape_values)  # sort SAPE values in ascending order\n",
        "        series_ranks = [sorted_sape.index(sape) + 1 for sape in sape_values]  # assign ranks to SAPE values\n",
        "        ranks.append(series_ranks)\n",
        "\n",
        "    mean_ranks = []  # to store mean ranks for each forecasting method\n",
        "\n",
        "    for method_index in range(num_methods):\n",
        "        total_rank = sum(ranks[series_index][method_index] for series_index in range(num_series))\n",
        "        mean_rank = total_rank / num_series\n",
        "        mean_ranks.append(mean_rank)\n",
        "\n",
        "    return mean_ranks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_pred(y_true, y_pred):\n",
        "    # Symmetric mean absolute percentage error\n",
        "    smape = evaluate_smape(y_true, y_pred)\n",
        "    # Median symmetric absolute percentage error\n",
        "    mdape = evaluate_mdape(y_true, y_pred)\n",
        "    return smape, mdape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(y_true_set, y_pred_set):\n",
        "    # Average Ranking\n",
        "    avg_ranking = None\n",
        "    # Percentage Better\n",
        "    percentage_better = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Destandardise\n",
        "def de_standardise(value):\n",
        "    return value * STD + MEAN\n",
        "\n",
        "def standardise(value):\n",
        "    return (value - MEAN) / STD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "Combination = namedtuple(\"Combination\", \"learning_rate batch_size regularization hidden_layers\")\n",
        "\n",
        "learning_rates = np.array([0.001, 0.01, 0.1])\n",
        "batch_sizes = np.array([16, 32, 64, 128, 256])\n",
        "regularizations = np.array([0.001, 0.01, 0.1])\n",
        "hidden_layers = np.array([2, 3, 4, 5, 6])\n",
        "\n",
        "combinations = list(itertools.starmap(Combination, itertools.product(learning_rates, batch_sizes, regularizations, hidden_layers)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 63ms/step\n",
            "test_y_cv[j]: 3268.5, predictions: 3474.0619057683134\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "test_y_cv[j]: 3470.22, predictions: 3525.2098148009272\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "test_y_cv[j]: 3659.18, predictions: 3632.2568560419136\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "test_y_cv[j]: 3964.26, predictions: 3755.0419146534987\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "test_y_cv[j]: 4264.36, predictions: 3931.5635946858665\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "test_y_cv[j]: 4863.74, predictions: 4115.062714989882\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 2301.45, predictions: 4456.965727634606\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "test_y_cv[j]: 2656.07, predictions: 3155.998823471119\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "test_y_cv[j]: 3028.4, predictions: 3043.155483115916\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "test_y_cv[j]: 3711.2, predictions: 3246.9118993823145\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "test_y_cv[j]: 4381.21, predictions: 3771.756426948695\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "test_y_cv[j]: 5215.0, predictions: 4186.093938667621\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "test_y_cv[j]: 4978.0, predictions: 4685.22759342525\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "test_y_cv[j]: 4644.0, predictions: 4622.04994694302\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "test_y_cv[j]: 5208.0, predictions: 4388.554597262086\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "test_y_cv[j]: 5467.0, predictions: 4609.206072730896\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "test_y_cv[j]: 5718.0, predictions: 4819.955315058369\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "test_y_cv[j]: 5956.0, predictions: 4998.415360823249\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "test_y_cv[j]: 6797.0, predictions: 5125.947285842497\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "test_y_cv[j]: 8529.0, predictions: 5585.1684357459635\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "test_y_cv[j]: 362.22000000000025, predictions: 5932.790513888673\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "test_y_cv[j]: 434.15999999999985, predictions: 2451.2999320148633\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "test_y_cv[j]: 495.96000000000004, predictions: 1905.971983081889\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "test_y_cv[j]: 554.1599999999999, predictions: 1849.864853280611\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "test_y_cv[j]: 655.71, predictions: 2033.3395086560922\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "test_y_cv[j]: 761.5500000000002, predictions: 2055.915245050196\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "test_y_cv[j]: 859.1399999999999, predictions: 2082.115568764182\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "test_y_cv[j]: 989.6399999999999, predictions: 2120.302305982111\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "test_y_cv[j]: 1816.92, predictions: 2172.3319883168906\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "test_y_cv[j]: 1920.66, predictions: 2612.476648279398\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "test_y_cv[j]: 2016.12, predictions: 2755.542675642246\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "test_y_cv[j]: 2091.3, predictions: 2812.7881710596566\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "test_y_cv[j]: 2206.68, predictions: 2824.087860417694\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "test_y_cv[j]: 3205.44, predictions: 2888.7151224661275\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "test_y_cv[j]: 1245.08, predictions: 3425.0498489772517\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "test_y_cv[j]: 1474.4300000000003, predictions: 2497.5350518492814\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "test_y_cv[j]: 1723.11, predictions: 2395.348305320981\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "test_y_cv[j]: 2042.25, predictions: 2501.75752180622\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "test_y_cv[j]: 2333.25, predictions: 2791.7672220042336\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "test_y_cv[j]: 2752.0, predictions: 2970.8190570242195\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "test_y_cv[j]: 3605.5, predictions: 3213.4309591776964\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "test_y_cv[j]: 4046.5, predictions: 3696.7135033957115\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "test_y_cv[j]: 4885.0, predictions: 4012.2427442092076\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "test_y_cv[j]: 6447.5, predictions: 4486.293906171808\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "test_y_cv[j]: 6472.0, predictions: 5366.147914890225\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 8373.0, predictions: 5534.552905494431\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "test_y_cv[j]: 8765.5, predictions: 5932.194824869119\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "test_y_cv[j]: 11467.0, predictions: 5934.269987026437\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "test_y_cv[j]: 1344.9700000000003, predictions: 5934.3448137567975\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 1417.1400000000003, predictions: 3188.3102608778336\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "test_y_cv[j]: 1554.67, predictions: 2129.117967253902\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 1740.1, predictions: 2044.6929416429398\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "test_y_cv[j]: 1886.05, predictions: 2608.3818956081577\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "test_y_cv[j]: 2291.72, predictions: 2703.0826786740695\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "test_y_cv[j]: 2387.7, predictions: 2927.5932148002457\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "test_y_cv[j]: 2913.2, predictions: 3015.1886270404434\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 3953.4, predictions: 3297.3953860469637\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "test_y_cv[j]: 5362.0, predictions: 3886.866200720666\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 5677.0, predictions: 4744.102093573508\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 6160.0, predictions: 5045.113212083045\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "test_y_cv[j]: 7157.0, predictions: 5288.582574944702\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "test_y_cv[j]: 3823.0, predictions: 5803.188667020585\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 2258.64, predictions: 4138.760303935031\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 2471.73, predictions: 2917.318432286408\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 2685.13, predictions: 2801.8109434744797\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "test_y_cv[j]: 3062.63, predictions: 3094.2179629335737\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "test_y_cv[j]: 3401.3, predictions: 3392.281225122735\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 3798.52, predictions: 3603.775870864304\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 4131.23, predictions: 3842.122009582079\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "test_y_cv[j]: 4582.09, predictions: 4045.0744650338293\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "test_y_cv[j]: 4856.5, predictions: 4305.182629919938\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "test_y_cv[j]: 4485.47, predictions: 4482.386707797027\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 4684.74, predictions: 4301.987869762898\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "test_y_cv[j]: 4926.51, predictions: 4344.780350662499\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 5028.27, predictions: 4481.217997138778\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "test_y_cv[j]: 5500.53, predictions: 4580.03095994831\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "test_y_cv[j]: 1822.88, predictions: 4831.943556576897\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "test_y_cv[j]: 1620.78, predictions: 2929.974386599155\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 2114.17, predictions: 2407.200176951441\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "test_y_cv[j]: 1857.05, predictions: 2616.760173923488\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "test_y_cv[j]: 2297.84, predictions: 2710.4927185973456\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 2802.01, predictions: 2925.060805261306\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "test_y_cv[j]: 3647.49, predictions: 3217.010577338778\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "test_y_cv[j]: 3712.98, predictions: 3733.243206325818\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "test_y_cv[j]: 4291.95, predictions: 3842.453641894776\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 4906.95, predictions: 4133.219104256203\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 4738.76, predictions: 4483.029193989967\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "test_y_cv[j]: 5335.95, predictions: 4460.880786472104\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 5774.62, predictions: 4731.164990617531\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "test_y_cv[j]: 6798.39, predictions: 5000.388763501981\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 1718.82, predictions: 5599.543211239519\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 1962.42, predictions: 3002.143061885734\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 2178.76, predictions: 2542.7998615417832\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "test_y_cv[j]: 2488.12, predictions: 2627.3396255348875\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "test_y_cv[j]: 2682.14, predictions: 3056.743724867204\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "test_y_cv[j]: 2645.94, predictions: 3182.717876790615\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "test_y_cv[j]: 2752.58, predictions: 3175.5569343215057\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "test_y_cv[j]: 2571.18, predictions: 3213.4869573578285\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "test_y_cv[j]: 2878.18, predictions: 3120.289716288388\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "test_y_cv[j]: 3138.36, predictions: 3264.1107746088155\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "test_y_cv[j]: 3358.42, predictions: 3430.628888557997\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "test_y_cv[j]: 3840.68, predictions: 3585.1942549385153\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "test_y_cv[j]: 4730.0, predictions: 3850.555829073895\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "test_y_cv[j]: 5360.6, predictions: 4362.563885887223\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "test_y_cv[j]: 2009.28, predictions: 4785.779973046587\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "test_y_cv[j]: 2207.48, predictions: 3063.889738550533\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-04917fe77fa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0moptimal_mdape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0moptimal_hyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0msmape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msmape\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0moptimal_smape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-04917fe77fa7>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(combination, train_x, train_y, tscv)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mmdape_scores_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_x_cv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0msmape_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmdape_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_standardise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y_cv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mde_standardise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"test_y_cv[j]: {de_standardise(test_y_cv[j])[0]}, predictions: {de_standardise(predictions).flatten()[0]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2347\u001b[0m                     )\n\u001b[1;32m   2348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2349\u001b[0;31m             data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[1;32m   2350\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1581\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1583\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1261\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mflat_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[0;34m(self, map_func, name)\u001b[0m\n\u001b[1;32m   2283\u001b[0m     \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mflat_map_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2285\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mflat_map_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2286\u001b[0m     \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/data/ops/flat_map_op.py\u001b[0m in \u001b[0;36m_flat_map\u001b[0;34m(input_dataset, map_func, name)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_flat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-private-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;34m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_FlatMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/data/ops/flat_map_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     self._map_func = structured_function.StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m     34\u001b[0m         map_func, self._transformation_name(), dataset=input_dataset)\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \"\"\"\n\u001b[0;32m--> 232\u001b[0;31m     concrete_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[1;32m    233\u001b[0m         *args, **kwargs)\n\u001b[1;32m    234\u001b[0m     \u001b[0mconcrete_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m       \u001b[0mconcrete_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0mconcrete_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arg_keywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_concrete_function_internal_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m           \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplaceholder_bound_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m           concrete_function = self._create_concrete_function(\n\u001b[0m\u001b[1;32m    397\u001b[0m               args, kwargs, func_graph)\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     concrete_function = monomorphic_function.ConcreteFunction(\n\u001b[0;32m--> 300\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1212\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    236\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    167\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_variables_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mslice_batch_indices\u001b[0;34m(indices)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \"\"\"\n\u001b[1;32m    326\u001b[0m             \u001b[0mnum_in_full_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_full_batches\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0mfirst_k_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnum_in_full_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m             first_k_indices = tf.reshape(\n\u001b[1;32m    329\u001b[0m                 \u001b[0mfirst_k_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnum_full_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mslice\u001b[0;34m(input_, begin, size, name)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m   \"\"\"\n\u001b[0;32m-> 1181\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(input, begin, size, name)\u001b[0m\n\u001b[1;32m   9611\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9612\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9613\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   9614\u001b[0m         \"Slice\", input=input, begin=begin, size=size, name=name)\n\u001b[1;32m   9615\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    775\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m       _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n\u001b[0m\u001b[1;32m    778\u001b[0m                              \u001b[0mkeywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_type_attr_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m                              input_types)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_ExtractInputsAndAttrs\u001b[0;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[0m\n\u001b[1;32m    548\u001b[0m                 preferred_dtype=default_dtype)\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m           values = ops.convert_to_tensor(\n\u001b[0m\u001b[1;32m    551\u001b[0m               \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m               \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1642\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    342\u001b[0m                                          as_ref=False):\n\u001b[1;32m    343\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m   \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    269\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    283\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 285\u001b[0;31m       tensor_util.make_tensor_proto(\n\u001b[0m\u001b[1;32m    286\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m           allow_broadcast=allow_broadcast))\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m   is_quantized = (\n\u001b[0;32m--> 489\u001b[0;31m       dtype in [\n\u001b[0m\u001b[1;32m    490\u001b[0m           \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquint16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m           \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqint32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtypes_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializedDType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;34m\"\"\"Returns True iff this DType refers to the same type as `other`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "eval_scores = []\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "def cross_validation(combination, train_x=train_x, train_y=train_y, tscv=tscv):\n",
        "    best_smape = float('inf')\n",
        "    best_hyperparameters = {}\n",
        "    hidden_neurons = np.arange(2, 9)\n",
        "    smape_scores = []\n",
        "    mdape_scores = []\n",
        "\n",
        "    # Cross-Validation\n",
        "    for train_index, test_index in tscv.split(train_x):\n",
        "        train_x_cv, test_x_cv = train_x[train_index], train_x[test_index]\n",
        "        train_y_cv, test_y_cv = train_y[train_index], train_y[test_index]\n",
        "        \n",
        "        # Create model with selected hyperparameters\n",
        "        model_cv = tf.keras.Sequential([\n",
        "            tf.keras.layers.Flatten(input_shape=(4, 1)),\n",
        "        ], name=\"model\")\n",
        "\n",
        "        chosen_hidden_neurons = []\n",
        "\n",
        "        for i in range(combination.hidden_layers):\n",
        "            random_neuron = random.choice(hidden_neurons)\n",
        "            chosen_hidden_neurons.append(random_neuron)\n",
        "            model_cv.add(tf.keras.layers.Dense(random_neuron, \n",
        "                                            activation=\"relu\", \n",
        "                                            kernel_initializer=tf.initializers.HeNormal(), \n",
        "                                            kernel_regularizer=tf.keras.regularizers.l2(combination.regularization)))\n",
        "        model_cv.add(tf.keras.layers.Dense(1, activation=\"linear\", \n",
        "                                        kernel_initializer=tf.initializers.HeNormal(), \n",
        "                                        kernel_regularizer=tf.keras.regularizers.l2(combination.regularization)))\n",
        "\n",
        "\n",
        "        model_cv.compile(loss=\"mse\",\n",
        "                        optimizer=tf.keras.optimizers.Adam(learning_rate=combination.learning_rate),\n",
        "                        metrics=[\"mse\", \"mae\"]) # Backpropagation\n",
        "        \n",
        "        model_cv.fit(train_x_cv, train_y_cv, epochs=30, batch_size=combination.batch_size, verbose=0)\n",
        "        smape_scores_fold = []\n",
        "        mdape_scores_fold = []\n",
        "        for j in range(len(test_x_cv)):\n",
        "            predictions = model_cv.predict(np.array([test_x_cv[j]]))\n",
        "            smape_score, mdape_score = evaluate_pred(de_standardise(test_y_cv[j])[0], de_standardise(predictions).flatten()[0])\n",
        "            print(f\"test_y_cv[j]: {de_standardise(test_y_cv[j])[0]}, predictions: {de_standardise(predictions).flatten()[0]}\")\n",
        "            smape_scores_fold.append(smape_score)\n",
        "            mdape_scores_fold.append(mdape_score)\n",
        "            #print(smape_score)\n",
        "        \n",
        "        smape_scores.append(np.mean(smape_scores_fold))\n",
        "        mdape_scores.append(np.mean(mdape_scores_fold))\n",
        "        \n",
        "    mean_smape = np.mean(smape_scores)\n",
        "    mean_mdape = np.mean(mdape_scores)\n",
        "    hyperparameters = {\n",
        "        'learning_rate': combination.learning_rate,\n",
        "        'batch_size': combination.batch_size,\n",
        "        'regularization': combination.regularization,\n",
        "        'hidden_neurons': chosen_hidden_neurons,\n",
        "        'hidden_layers': combination.hidden_layers\n",
        "    }\n",
        "    print(f\"Current mean SMAPE: {mean_smape}, Current hyperparameters: {hyperparameters}\")\n",
        "    return mean_smape, mean_mdape, hyperparameters\n",
        "\n",
        "random_combinations = random.sample(combinations, 1)\n",
        "results = map(cross_validation, random_combinations)\n",
        "\n",
        "optimal_smape = float('inf')\n",
        "optimal_mdape = float('inf')\n",
        "optimal_hyperparameters = {}\n",
        "for result in results:\n",
        "    smape, mdape, hyperparameters = result\n",
        "    if smape < optimal_smape:\n",
        "        optimal_smape = smape\n",
        "        optimal_mdape = mdape\n",
        "        optimal_hyperparameters = hyperparameters\n",
        "print(\"Best Hyperparameters:\", optimal_hyperparameters)\n",
        "print(\"Best SMAPE Score:\", optimal_smape)\n",
        "print(\"Best MDAPE Score:\", optimal_mdape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 551,
      "metadata": {
        "id": "u4z0s2GEn4gr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Regularization: 0.001\n",
            "Learning Rate: 0.01\n",
            "Batch Size: 32\n",
            "Hidden Neurons 2 in Layer 1.\n",
            "Hidden Neurons 7 in Layer 2.\n",
            "\n",
            "Epoch 1/50\n",
            "38/64 [================>.............] - ETA: 0s - loss: 0.8392 - mse: 0.8240 - mae: 0.6140 WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 1s 1ms/step - loss: 0.7296 - mse: 0.7151 - mae: 0.5659\n",
            "Epoch 2/50\n",
            "36/64 [===============>..............] - ETA: 0s - loss: 0.6245 - mse: 0.6122 - mae: 0.5046WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.5776 - mse: 0.5656 - mae: 0.4831\n",
            "Epoch 3/50\n",
            "44/64 [===================>..........] - ETA: 0s - loss: 0.5208 - mse: 0.5098 - mae: 0.4278WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4935 - mse: 0.4827 - mae: 0.4201\n",
            "Epoch 4/50\n",
            "38/64 [================>.............] - ETA: 0s - loss: 0.4128 - mse: 0.4026 - mae: 0.3790WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4504 - mse: 0.4403 - mae: 0.3729\n",
            "Epoch 5/50\n",
            "45/64 [====================>.........] - ETA: 0s - loss: 0.4141 - mse: 0.4047 - mae: 0.3710WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4327 - mse: 0.4234 - mae: 0.3613\n",
            "Epoch 6/50\n",
            "44/64 [===================>..........] - ETA: 0s - loss: 0.4382 - mse: 0.4295 - mae: 0.3538WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4216 - mse: 0.4130 - mae: 0.3547\n",
            "Epoch 7/50\n",
            "37/64 [================>.............] - ETA: 0s - loss: 0.4497 - mse: 0.4417 - mae: 0.3723WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4218 - mse: 0.4138 - mae: 0.3624\n",
            "Epoch 8/50\n",
            "35/64 [===============>..............] - ETA: 0s - loss: 0.4123 - mse: 0.4046 - mae: 0.3416WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.4139 - mse: 0.4064 - mae: 0.3530\n",
            "Epoch 9/50\n",
            "38/64 [================>.............] - ETA: 0s - loss: 0.4609 - mse: 0.4538 - mae: 0.3678WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4152 - mse: 0.4082 - mae: 0.3590\n",
            "Epoch 10/50\n",
            "40/64 [=================>............] - ETA: 0s - loss: 0.4682 - mse: 0.4614 - mae: 0.3754WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4133 - mse: 0.4066 - mae: 0.3583\n",
            "Epoch 11/50\n",
            "34/64 [==============>...............] - ETA: 0s - loss: 0.4658 - mse: 0.4595 - mae: 0.3619WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4115 - mse: 0.4053 - mae: 0.3520\n",
            "Epoch 12/50\n",
            "45/64 [====================>.........] - ETA: 0s - loss: 0.4210 - mse: 0.4150 - mae: 0.3564WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4103 - mse: 0.4044 - mae: 0.3582\n",
            "Epoch 13/50\n",
            "61/64 [===========================>..] - ETA: 0s - loss: 0.4138 - mse: 0.4081 - mae: 0.3493WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 3ms/step - loss: 0.4074 - mse: 0.4016 - mae: 0.3489\n",
            "Epoch 14/50\n",
            "54/64 [========================>.....] - ETA: 0s - loss: 0.4143 - mse: 0.4088 - mae: 0.3607WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 968us/step - loss: 0.4100 - mse: 0.4045 - mae: 0.3557\n",
            "Epoch 15/50\n",
            "63/64 [============================>.] - ETA: 0s - loss: 0.4068 - mse: 0.4015 - mae: 0.3498WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 861us/step - loss: 0.4074 - mse: 0.4021 - mae: 0.3507\n",
            "Epoch 16/50\n",
            "61/64 [===========================>..] - ETA: 0s - loss: 0.4048 - mse: 0.3997 - mae: 0.3488WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 880us/step - loss: 0.4071 - mse: 0.4020 - mae: 0.3510\n",
            "Epoch 17/50\n",
            "56/64 [=========================>....] - ETA: 0s - loss: 0.4207 - mse: 0.4157 - mae: 0.3529WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 952us/step - loss: 0.4067 - mse: 0.4018 - mae: 0.3485\n",
            "Epoch 18/50\n",
            "60/64 [===========================>..] - ETA: 0s - loss: 0.4143 - mse: 0.4095 - mae: 0.3503WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 901us/step - loss: 0.4064 - mse: 0.4017 - mae: 0.3477\n",
            "Epoch 19/50\n",
            "62/64 [============================>.] - ETA: 0s - loss: 0.4056 - mse: 0.4009 - mae: 0.3487WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 880us/step - loss: 0.4084 - mse: 0.4038 - mae: 0.3511\n",
            "Epoch 20/50\n",
            "62/64 [============================>.] - ETA: 0s - loss: 0.4065 - mse: 0.4019 - mae: 0.3563WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 864us/step - loss: 0.4095 - mse: 0.4049 - mae: 0.3572\n",
            "Epoch 21/50\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4053 - mse: 0.4008 - mae: 0.3460WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 850us/step - loss: 0.4053 - mse: 0.4008 - mae: 0.3460\n",
            "Epoch 22/50\n",
            "53/64 [=======================>......] - ETA: 0s - loss: 0.4249 - mse: 0.4205 - mae: 0.3568WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4082 - mse: 0.4038 - mae: 0.3543\n",
            "Epoch 23/50\n",
            "44/64 [===================>..........] - ETA: 0s - loss: 0.4355 - mse: 0.4311 - mae: 0.3610WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4088 - mse: 0.4044 - mae: 0.3572\n",
            "Epoch 24/50\n",
            "62/64 [============================>.] - ETA: 0s - loss: 0.4075 - mse: 0.4033 - mae: 0.3501WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 868us/step - loss: 0.4073 - mse: 0.4030 - mae: 0.3506\n",
            "Epoch 25/50\n",
            "57/64 [=========================>....] - ETA: 0s - loss: 0.4243 - mse: 0.4200 - mae: 0.3588WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4087 - mse: 0.4044 - mae: 0.3552\n",
            "Epoch 26/50\n",
            "37/64 [================>.............] - ETA: 0s - loss: 0.3956 - mse: 0.3913 - mae: 0.3590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.4081 - mse: 0.4039 - mae: 0.3542\n",
            "Epoch 27/50\n",
            "33/64 [==============>...............] - ETA: 0s - loss: 0.3439 - mse: 0.3396 - mae: 0.3284WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4061 - mse: 0.4019 - mae: 0.3485\n",
            "Epoch 28/50\n",
            "39/64 [=================>............] - ETA: 0s - loss: 0.4287 - mse: 0.4245 - mae: 0.3501WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4067 - mse: 0.4025 - mae: 0.3513\n",
            "Epoch 29/50\n",
            "42/64 [==================>...........] - ETA: 0s - loss: 0.4344 - mse: 0.4302 - mae: 0.3433WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4042 - mse: 0.4000 - mae: 0.3441\n",
            "Epoch 30/50\n",
            "37/64 [================>.............] - ETA: 0s - loss: 0.4547 - mse: 0.4506 - mae: 0.3649WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4062 - mse: 0.4020 - mae: 0.3524\n",
            "Epoch 31/50\n",
            "46/64 [====================>.........] - ETA: 0s - loss: 0.4114 - mse: 0.4072 - mae: 0.3528WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4056 - mse: 0.4014 - mae: 0.3518\n",
            "Epoch 32/50\n",
            "43/64 [===================>..........] - ETA: 0s - loss: 0.4311 - mse: 0.4271 - mae: 0.3540WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4035 - mse: 0.3995 - mae: 0.3485\n",
            "Epoch 33/50\n",
            "43/64 [===================>..........] - ETA: 0s - loss: 0.3481 - mse: 0.3440 - mae: 0.3321WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4049 - mse: 0.4009 - mae: 0.3492\n",
            "Epoch 34/50\n",
            "38/64 [================>.............] - ETA: 0s - loss: 0.3396 - mse: 0.3355 - mae: 0.3350WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4040 - mse: 0.4000 - mae: 0.3485\n",
            "Epoch 35/50\n",
            "41/64 [==================>...........] - ETA: 0s - loss: 0.4041 - mse: 0.4000 - mae: 0.3401WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4037 - mse: 0.3996 - mae: 0.3438\n",
            "Epoch 36/50\n",
            "44/64 [===================>..........] - ETA: 0s - loss: 0.3584 - mse: 0.3544 - mae: 0.3434WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4043 - mse: 0.4003 - mae: 0.3480\n",
            "Epoch 37/50\n",
            "33/64 [==============>...............] - ETA: 0s - loss: 0.3283 - mse: 0.3243 - mae: 0.3278WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.4043 - mse: 0.4003 - mae: 0.3470\n",
            "Epoch 38/50\n",
            "39/64 [=================>............] - ETA: 0s - loss: 0.3991 - mse: 0.3952 - mae: 0.3668WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4051 - mse: 0.4012 - mae: 0.3491\n",
            "Epoch 39/50\n",
            "39/64 [=================>............] - ETA: 0s - loss: 0.4448 - mse: 0.4408 - mae: 0.3590WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4054 - mse: 0.4015 - mae: 0.3520\n",
            "Epoch 40/50\n",
            "45/64 [====================>.........] - ETA: 0s - loss: 0.4025 - mse: 0.3986 - mae: 0.3395WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4054 - mse: 0.4015 - mae: 0.3462\n",
            "Epoch 41/50\n",
            "51/64 [======================>.......] - ETA: 0s - loss: 0.3441 - mse: 0.3402 - mae: 0.3291WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4032 - mse: 0.3993 - mae: 0.3448\n",
            "Epoch 42/50\n",
            "41/64 [==================>...........] - ETA: 0s - loss: 0.4082 - mse: 0.4043 - mae: 0.3339WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4053 - mse: 0.4015 - mae: 0.3495\n",
            "Epoch 43/50\n",
            "47/64 [=====================>........] - ETA: 0s - loss: 0.4411 - mse: 0.4373 - mae: 0.3619WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4043 - mse: 0.4005 - mae: 0.3476\n",
            "Epoch 44/50\n",
            "46/64 [====================>.........] - ETA: 0s - loss: 0.4444 - mse: 0.4405 - mae: 0.3614WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4056 - mse: 0.4017 - mae: 0.3522\n",
            "Epoch 45/50\n",
            "47/64 [=====================>........] - ETA: 0s - loss: 0.4352 - mse: 0.4314 - mae: 0.3562WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4047 - mse: 0.4009 - mae: 0.3452\n",
            "Epoch 46/50\n",
            "46/64 [====================>.........] - ETA: 0s - loss: 0.4368 - mse: 0.4330 - mae: 0.3574WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4036 - mse: 0.3998 - mae: 0.3479\n",
            "Epoch 47/50\n",
            "51/64 [======================>.......] - ETA: 0s - loss: 0.4114 - mse: 0.4075 - mae: 0.3500WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4066 - mse: 0.4028 - mae: 0.3500\n",
            "Epoch 48/50\n",
            "48/64 [=====================>........] - ETA: 0s - loss: 0.3654 - mse: 0.3616 - mae: 0.3480WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4037 - mse: 0.3999 - mae: 0.3464\n",
            "Epoch 49/50\n",
            "49/64 [=====================>........] - ETA: 0s - loss: 0.4122 - mse: 0.4085 - mae: 0.3448WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 1ms/step - loss: 0.4067 - mse: 0.4030 - mae: 0.3538\n",
            "Epoch 50/50\n",
            "50/64 [======================>.......] - ETA: 0s - loss: 0.3974 - mse: 0.3936 - mae: 0.3432WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "64/64 [==============================] - 0s 2ms/step - loss: 0.4045 - mse: 0.4008 - mae: 0.3479\n",
            "[[-1.28740269 -1.21687544 -1.13856182 -1.0407236 ]\n",
            " [-1.21687544 -1.13856182 -1.0407236  -0.92424603]\n",
            " [-1.13856182 -1.0407236  -0.92424603 -0.75062769]\n",
            " ...\n",
            " [-0.61201865 -0.67357104 -0.27405519 -0.33851768]\n",
            " [-0.67357104 -0.27405519 -0.33851768 -0.50434476]\n",
            " [-0.27405519 -0.33851768 -0.50434476 -0.27173199]]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Regularization: {optimal_hyperparameters['regularization']}\")\n",
        "print(f\"Learning Rate: {optimal_hyperparameters['learning_rate']}\")\n",
        "print(f\"Batch Size: {optimal_hyperparameters['batch_size']}\")\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(4, 1)),\n",
        "], name=\"model\")\n",
        "\n",
        "for i in range(optimal_hyperparameters[\"hidden_layers\"]):\n",
        "    print(f\"Hidden Neurons {optimal_hyperparameters['hidden_neurons'][i]} in Layer {i+1}.\")\n",
        "    model.add(tf.keras.layers.Dense(optimal_hyperparameters[\"hidden_neurons\"][i], \n",
        "                                    activation=\"relu\", \n",
        "                                    kernel_initializer=tf.initializers.HeNormal(), \n",
        "                                    kernel_regularizer=tf.keras.regularizers.l2(optimal_hyperparameters[\"regularization\"])))\n",
        "model.add(tf.keras.layers.Dense(1, activation=\"linear\", \n",
        "                                kernel_initializer=tf.initializers.HeNormal(), \n",
        "                                kernel_regularizer=tf.keras.regularizers.l2(optimal_hyperparameters[\"regularization\"])))\n",
        "\n",
        "print()\n",
        "model.compile(loss=\"mse\",\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=optimal_hyperparameters[\"learning_rate\"]), \n",
        "                metrics=[\"mse\", \"mae\"]) # Backpropagation\n",
        "\n",
        "# Train the model on the full training dataset\n",
        "model.fit(train_x, train_y, epochs=50, batch_size=optimal_hyperparameters[\"batch_size\"], verbose=1, callbacks=[create_model_checkpoint(model_name=model.name)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 552,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 63ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([4802.48985437])"
            ]
          },
          "execution_count": 552,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def autoregression(model, x, horizon=6):\n",
        "    standardised_x = standardise(x)\n",
        "    for i in range(horizon):\n",
        "        forecast = model.predict(np.array([standardised_x[i:i+4]]))\n",
        "        pred = np.array([tf.squeeze(forecast).numpy()])\n",
        "        standardised_x = np.concatenate((standardised_x, pred))\n",
        "    return de_standardise(standardised_x[-horizon:])\n",
        "\n",
        "autoregression(model, np.array([4793.2, 5602, 5065, 5056]), 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 510,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-1.21687544 -1.13856182 -1.0407236  -0.92424603]]\n",
            "1/1 [==============================] - 0s 53ms/step\n"
          ]
        }
      ],
      "source": [
        "data = (np.array([[940.66, 1084.86, 1244.98, 1445.02]]) - scaler.mean_) / scaler.scale_\n",
        "print(data.shape)\n",
        "#def make_preds(model, input_data):\n",
        "#  forecast = model.predict(input_data)\n",
        "#  preds = tf.squeeze(forecast)\n",
        "#  return preds\n",
        "\n",
        "#pred = make_preds(model, data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 511,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 4)"
            ]
          },
          "execution_count": 511,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array([[940.66, 1084.86, 1244.98, 1445.02]]).shape\n",
        "#autoregression(model, test2_x[1], 1)\n",
        "#standardised_x = np.array(standardise(test2_x[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1084.86, 1244.98, 1445.02])"
            ]
          },
          "execution_count": 251,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array = np.array([[940.66, 1084.86, 1244.98, 1445.02]])\n",
        "array[0][1:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SInanWFa8qIZ",
        "outputId": "c2d65ad7-6fe9-45ff-8898-20b21197b221"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-1.28740269 -1.21687544 -1.13856182 -1.0407236 ]]\n",
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 512,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds7L0_rE-g4Z",
        "outputId": "a86889ff-fd57-49ec-c83d-c52f549b126c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1897.52436208])"
            ]
          },
          "execution_count": 512,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inversed = de_standardise(np.array(pred))\n",
        "inversed"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
