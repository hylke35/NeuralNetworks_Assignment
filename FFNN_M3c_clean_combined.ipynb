{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import seaborn\n",
    "import numpy as np\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "* Try K-fold per timeseries instead of timestep and shuffle\n",
    "* Make overview of smape scores in validation\n",
    "* Experiment with regularization\n",
    "* Experiment  with different window size\n",
    "* Smoothing\n",
    "voor volgende keer:\n",
    "shuffel moet de dataframes returenen dan kunnen die door df_to_observations heen\n",
    "dan krijg je dus train_observations en validation_observation en daar kunnen dan x_train en y_trian uit gehaald worden\n",
    "eerst wel y_validation_final er uit halen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fixed-window sequences for training and validation data\n",
    "def create_sequences(X, window_size):\n",
    "    seq_X = []\n",
    "    seq_y = []\n",
    "    for i in range(len(X) - window_size):\n",
    "        seq_X.append(X[i:i+window_size])\n",
    "        seq_y.append(X[i+window_size])\n",
    "    return seq_X, seq_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reprocess(y, details):\n",
    "    # print(details)\n",
    "    mean = details[2][0]\n",
    "    std = details[2][1]\n",
    "    PF = details[2][2]\n",
    "    PFtype = details[2][3]\n",
    "    time = details[3]\n",
    "\n",
    "    # print(\"mean:\", mean, \"std:\", std, \"PF\", PF, \"type\", PFtype, \"time\", time)\n",
    "\n",
    "    if(PFtype == 1):\n",
    "        return ((y * std) + mean) * np.exp(PF[0] * time + PF[1])    \n",
    "    # print(\"here\")\n",
    "    return (y * std + mean) * (PF[0] * np.square(time) + PF[1] * time + PF[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    PFtype = -1\n",
    "    PF1 = np.polyfit(np.linspace(0,len(data) - 1,num=len(data)), np.log(data), 1)\n",
    "    PF2 = np.polyfit(np.linspace(0,len(data) - 1,num=len(data)),data, 2)\n",
    "    error1 = data - (np.exp(PF1[0] * np.linspace(0, len(data) - 1, num=len(data)) + PF1[1]))\n",
    "    error2 = data - (PF2[0] * np.square(np.linspace(0,len(data) - 1,num=len(data))) + PF2[1] * np.linspace(0, len(data) - 1, num=len(data)) + PF2[2])\n",
    "    \n",
    "    #Otto: dit is de keuze voro welke je preporcessed. je kan die plotjes un commenten om de fit te zien\n",
    "    if(np.sum(np.square(error1)) < np.sum(np.square(error2))):\n",
    "        PF = PF1\n",
    "        preprocessed = data / (np.exp(PF[0] * np.linspace(0,len(data) - 1,num=len(data)) + PF[1]))\n",
    "        PFtype = 1\n",
    "    else:\n",
    "        PF = PF2\n",
    "        preprocessed = data / (PF2[0] * np.square(np.linspace(0,len(data) - 1,num=len(data))) + PF2[1] * np.linspace(0,len(data) - 1,num=len(data)) + PF2[2])\n",
    "        PFtype = 2\n",
    "    \n",
    "    m = np.mean(preprocessed)\n",
    "    s = np.std(preprocessed)\n",
    "    preprocessed = (preprocessed - m)/s\n",
    "    details = [m, s, PF, PFtype]\n",
    "    \n",
    "    return preprocessed, details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess2(data):\n",
    "\n",
    "    PF = np.polyfit(np.linspace(0,len(data),num=len(data)), np.log(data), 1)\n",
    "\n",
    "    preprocessed = data / (np.exp(PF[0] * np.linspace(0,len(data),num=len(data)) + PF[1]))\n",
    "    m = np.mean(preprocessed)\n",
    "    s = np.std(preprocessed)\n",
    "    preprocessed = (preprocessed - m)/s\n",
    "\n",
    "    details = [m, s, PF]\n",
    "\n",
    "    return preprocessed, details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_clean(y_true, y_pred):\n",
    "    smape = 100 * np.mean(2*np.abs(y_pred - y_true) / (y_true + y_pred))\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(model, validation):\n",
    "    validation_x = []\n",
    "    validation_y = []\n",
    "    for val in validation:\n",
    "        validation_x.append(val[0])\n",
    "        validation_y.append(val[1])\n",
    "    validation_x = np.array(validation_x)\n",
    "    validation_y = np.array(validation_y)\n",
    "    smape = 0\n",
    "    prediction = model.predict(validation_x, verbose=0)\n",
    "    # _, acc = model.evaluate(validation_x, validation_y, verbose = 0)\n",
    "\n",
    "    # print(\"sse val is; \", np.sum(np.square(validation_y - prediction))/len(validation_y), \"val is \", acc)\n",
    "    for i in range(len(validation)):\n",
    "        observation = validation[i]\n",
    "        pred = prediction[i]\n",
    "        #print(pred, observation[1], pred - observation[1])\n",
    "        x_hat = reprocess(pred, observation)\n",
    "        x = reprocess(observation[1], observation)\n",
    "        #print(x_hat, x, x_hat - x)\n",
    "\n",
    "        smape += 2*np.abs(x_hat-x)/(x+x_hat)\n",
    "\n",
    "    smape /= len(validation)\n",
    "    smape *=100\n",
    "\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(x_train, y_train, x_validation, y_validation, window_size, options): #x_validation, y_validation\n",
    "    # Build the FFNN model\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(window_size, 1))) \n",
    "    model.add(keras.layers.Dense(options.layers[0], activation='sigmoid'))\n",
    "\n",
    "    if len(options.layers) > 2:\n",
    "        for i in range(1,len(options.layers)-1):\n",
    "            model.add(keras.layers.Dense(options.layers[i], activation=options.activation))\n",
    "                \n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "    #early stopping and saving the best model SOURCE: https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=50, min_delta=0.001)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=0, save_best_only=True)\n",
    "    # fit model\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(x_train, y_train, validation_data=(x_validation, y_validation), batch_size=options.batchSize, verbose = 0, callbacks=[es, mc], epochs= 1000) #fit the model with early stop\n",
    "\n",
    "    ##this is the best model\n",
    "    saved_model = load_model(\"best_model.h5\")\n",
    "\n",
    "    _, train_acc = saved_model.evaluate(x_train, y_train, verbose = 0)\n",
    "    _, test_acc = saved_model.evaluate(x_validation, y_validation, verbose = 0)\n",
    "\n",
    "    print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "\n",
    "    # plot the different accuracies. maybe then dont do a early stop. \n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='validation')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "\n",
    "    return saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"M3C.xls\")\n",
    "df = df.iloc[:146,6:26]\n",
    "\n",
    "df_train = df.iloc[:,:14]\n",
    "df_test = df.iloc[:,14:]\n",
    "\n",
    "window_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_observations(data, window_size):\n",
    "    observations = []\n",
    "    details = []\n",
    "    for index, row in data.iterrows():\n",
    "        preprocessed, detail = preprocess(np.array(row))\n",
    "        details.append(detail)\n",
    "        for i in range(len(preprocessed) - window_size):\n",
    "            observations.append([preprocessed[i:i+window_size],preprocessed[i+window_size], detail, i+window_size])\n",
    "\n",
    "    return observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(data, v, shuf):\n",
    "    data = np.array(data)  \n",
    "    if shuf:\n",
    "        np.random.shuffle(data)\n",
    "    else: \n",
    "        for index, row in pd.DataFrame(data).iterrows():\n",
    "            data = preprocess(row)\n",
    "    train = data[:int(np.floor(len(data)*(1-v)))]\n",
    "    validation = data[int(np.floor(len(data)*(1-v))):]\n",
    "    return train, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29, 58, 87, 116, 145]\n"
     ]
    }
   ],
   "source": [
    "def get_folds(rows, k):\n",
    "    folds = []\n",
    "    rows = np.array_split(np.arange(rows), k)\n",
    "    for row in rows:\n",
    "        folds.append(row[-1])\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfolds(df_train, k, options, fold_type, window_size):\n",
    "    avgSmape = []\n",
    "    train, final_validation = shuffle(df_train, 0.1,True)\n",
    "    folds = get_folds(len(train), k)\n",
    "    for fold in folds:\n",
    "        if fold_type == 1:\n",
    "            validationSet = []\n",
    "            x_train = []\n",
    "            y_train = []\n",
    "            observations = df_to_observations(df_train, window_size)\n",
    "            for i in range(0, len(observations), (14 - window_size)):\n",
    "                validationSet.append(observations[fold + i])\n",
    "                #print(\"appended to validation set obseravtion\", observations[fold + i])\n",
    "                #print(\"appended to train set observation \", end=\"\")\n",
    "                for j in range(fold):\n",
    "                    #print(observations[j + i][0], observations[j + i][1] )\n",
    "                    x_train.append(observations[j + i][0])\n",
    "                    y_train.append(observations[j + i][1])\n",
    "            x_train = np.array(x_train)\n",
    "            y_train = np.array(y_train)\n",
    "            #otto: we should shuffel here (maby make df first, shuffel and then tear it appart again, y and x should stay together)\n",
    "        elif fold_type == 2:\n",
    "            x_train = []\n",
    "            y_train= []\n",
    "            fold_train, fold_validation = shuffle(train[:fold],0.1,False)\n",
    "            for i in range(len(fold_train)):\n",
    "                for j in range(train.shape[1]- window_size):\n",
    "                    x_train.append(fold_train[i][j:j+window_size])\n",
    "                    y_train.append(fold_train[i][j+window_size])\n",
    "\n",
    "            validationSet = df_to_observations(pd.DataFrame(fold_validation), window_size)\n",
    "            x_train = np.array(x_train)#.reshape(len(x_train),window_size)\n",
    "            y_train = np.array(y_train)\n",
    "\n",
    "        ##extract validation info for early stop. \n",
    "        x_validation = []\n",
    "        y_validation = []\n",
    "        for valObs in validationSet:\n",
    "            x_validation.append(valObs[0])\n",
    "            y_validation.append(valObs[1])\n",
    "        x_validation = np.array(x_validation)\n",
    "        y_validation = np.array(y_validation)\n",
    "        print(validationSet)\n",
    "\n",
    "        model = build_model(x_train, y_train, x_validation, y_validation, window_size, options)\n",
    "        #now estimate with the model on the validation set\n",
    "        validationPredicition = model.predict(x_validation, verbose=0)\n",
    "        yHatReal = []\n",
    "        yReal = []\n",
    "        for i in range(len(validationSet)):\n",
    "            yReal.append(reprocess(y_validation[i], validationSet[i]))\n",
    "            yHatReal.append(reprocess(validationPredicition[i], validationSet[i]) )\n",
    "        smapeVal = 0\n",
    "        for i in range(len(yReal)):\n",
    "            smapeVal += smape_clean(yReal[i], yHatReal[i])\n",
    "        smapeVal /= len(yReal)\n",
    "        print(\"smape equals\", smapeVal, \"with\", fold, \"time step as training\")\n",
    "        avgSmape.append(smapeVal)\n",
    "    return np.mean(avgSmape), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   layers activation  batchSize  averageSmape  varianceSmape\n",
      "0  [2, 2]       relu         16             0              0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "loop of ufunc does not support argument 0 of type float which has no callable log method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'log'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(options)\n\u001b[1;32m      5\u001b[0m window_size \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m----> 6\u001b[0m smape \u001b[39m=\u001b[39m kfolds(df_train, \u001b[39m5\u001b[39;49m, options\u001b[39m.\u001b[39;49miloc[\u001b[39m0\u001b[39;49m], \u001b[39m2\u001b[39;49m, window_size)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(smape)\n",
      "Cell \u001b[0;32mIn[67], line 31\u001b[0m, in \u001b[0;36mkfolds\u001b[0;34m(df_train, k, options, fold_type, window_size)\u001b[0m\n\u001b[1;32m     28\u001b[0m         x_train\u001b[39m.\u001b[39mappend(fold_train[i][j:j\u001b[39m+\u001b[39mwindow_size])\n\u001b[1;32m     29\u001b[0m         y_train\u001b[39m.\u001b[39mappend(fold_train[i][j\u001b[39m+\u001b[39mwindow_size])\n\u001b[0;32m---> 31\u001b[0m validationSet \u001b[39m=\u001b[39m df_to_observations(pd\u001b[39m.\u001b[39;49mDataFrame(fold_validation), window_size)\n\u001b[1;32m     32\u001b[0m x_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(x_train)\u001b[39m#.reshape(len(x_train),window_size)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m y_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(y_train)\n",
      "Cell \u001b[0;32mIn[28], line 5\u001b[0m, in \u001b[0;36mdf_to_observations\u001b[0;34m(data, window_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m details \u001b[39m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39miterrows():\n\u001b[0;32m----> 5\u001b[0m     preprocessed, detail \u001b[39m=\u001b[39m preprocess(np\u001b[39m.\u001b[39;49marray(row))\n\u001b[1;32m      6\u001b[0m     details\u001b[39m.\u001b[39mappend(detail)\n\u001b[1;32m      7\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(preprocessed) \u001b[39m-\u001b[39m window_size):\n",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess\u001b[39m(data):\n\u001b[1;32m      2\u001b[0m     PFtype \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m----> 3\u001b[0m     PF1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mpolyfit(np\u001b[39m.\u001b[39mlinspace(\u001b[39m0\u001b[39m,\u001b[39mlen\u001b[39m(data) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m,num\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(data)), np\u001b[39m.\u001b[39;49mlog(data), \u001b[39m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m     PF2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mpolyfit(np\u001b[39m.\u001b[39mlinspace(\u001b[39m0\u001b[39m,\u001b[39mlen\u001b[39m(data) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m,num\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(data)),data, \u001b[39m2\u001b[39m)\n\u001b[1;32m      5\u001b[0m     error1 \u001b[39m=\u001b[39m data \u001b[39m-\u001b[39m (np\u001b[39m.\u001b[39mexp(PF1[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mlinspace(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(data) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, num\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(data)) \u001b[39m+\u001b[39m PF1[\u001b[39m1\u001b[39m]))\n",
      "\u001b[0;31mTypeError\u001b[0m: loop of ufunc does not support argument 0 of type float which has no callable log method"
     ]
    }
   ],
   "source": [
    "options = [[[2,2],'relu',16,0,0]]\n",
    "options = pd.DataFrame(options)\n",
    "options = options.set_axis(['layers', 'activation', 'batchSize', 'averageSmape', 'varianceSmape'], axis=1)\n",
    "print(options)\n",
    "window_size = 3\n",
    "smape = kfolds(df_train, 5, options.iloc[0], 2, window_size)\n",
    "print(smape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "kfolds() missing 2 required positional arguments: 'fold_type' and 'window_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m smape_avg\u001b[39m=\u001b[39m[]\n\u001b[1;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m):\n\u001b[0;32m---> 22\u001b[0m     smp, model \u001b[39m=\u001b[39m kfolds(df_train, [\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m3\u001b[39;49m,\u001b[39m4\u001b[39;49m,\u001b[39m5\u001b[39;49m,\u001b[39m6\u001b[39;49m,\u001b[39m7\u001b[39;49m,\u001b[39m8\u001b[39;49m,\u001b[39m9\u001b[39;49m,\u001b[39m10\u001b[39;49m], options\u001b[39m.\u001b[39;49miloc[i])\n\u001b[1;32m     23\u001b[0m     smape_avg\u001b[39m.\u001b[39mappend(smp)\n\u001b[1;32m     25\u001b[0m options\u001b[39m.\u001b[39miat[i,\u001b[39m3\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(smape_avg)\n",
      "\u001b[0;31mTypeError\u001b[0m: kfolds() missing 2 required positional arguments: 'fold_type' and 'window_size'"
     ]
    }
   ],
   "source": [
    "lays = [[10], [2,2], [3,2], [4,4,4], [10,10,10]]\n",
    "epochs = [50]\n",
    "batchSizes = [16]\n",
    "activationFunctions = ['relu']\n",
    "\n",
    "options = []\n",
    "\n",
    "for layer in lays:\n",
    "    for activation in activationFunctions:\n",
    "        for batchSize in batchSizes:\n",
    "                options.append([layer, activation, batchSize, 0, 0])\n",
    "\n",
    "\n",
    "options = pd.DataFrame(options)\n",
    "options = options.set_axis(['layers', 'activation', 'batchSize', 'averageSmape', 'varianceSmape'], axis=1)\n",
    "\n",
    "# print(options.iloc[0].layers)\n",
    "\n",
    "for i in range(len(options)):\n",
    "    smape_avg=[]\n",
    "    for j in range(1):\n",
    "        smp, model = kfolds(df_train, [1,2,3,4,5,6,7,8,9,10], options.iloc[i])\n",
    "        smape_avg.append(smp)\n",
    "\n",
    "    options.iat[i,3] = np.mean(smape_avg)\n",
    "    options.iat[i,4] = np.std(smape_avg)\n",
    "\n",
    "\n",
    "op = pd.DataFrame(options)\n",
    "res = op.sort_values(by=\"averageSmape\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(op.sort_values(by=\"averageSmape\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TESTING\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "observations = []\n",
    "window_size = 3\n",
    "\n",
    "df_full = pd.DataFrame()\n",
    "df_full = df_train\n",
    "df_full = df_full.drop(df_full.columns[14:], axis=1)\n",
    "\n",
    "num_predictions = 6\n",
    "\n",
    "# Make predictions using autoregressive approach\n",
    "for pred in range(num_predictions):\n",
    "\n",
    "    PF = []\n",
    "    for index, row in df_full.iterrows():\n",
    "        preprocessed, details = preprocess(np.array(row))\n",
    "        PF.append(details[2:])\n",
    "        observations.append([preprocessed[11+pred:14+pred],0, details, 14+pred]) #y is unknown and first time point to predict is 15(or 14?)`\n",
    "\n",
    "    # Reshape the input for prediction\n",
    "    x = []\n",
    "    for i in (range(len(observations))):\n",
    "        x.append(observations[i][0])\n",
    "    x = np.array(x).reshape(len(x),window_size)\n",
    "    \n",
    "    # Make the prediction\n",
    "    prediction = model.predict(x)\n",
    "\n",
    "    y_u = []\n",
    "    for i in range(len(prediction)):\n",
    "        y_u.append(reprocess(prediction[i], observations[i]))\n",
    "\n",
    "    # print(pd.DataFrame(y_u).shape)\n",
    "    predictions[15+pred] = pd.DataFrame(pd.DataFrame(y_u))\n",
    "    df_full[15+pred] = pd.DataFrame(y_u)\n",
    "\n",
    "smapes = pd.DataFrame(columns=[i for i in range(num_predictions)])\n",
    "\n",
    "for i in range(predictions.shape[0]):\n",
    "    smape_row = []\n",
    "    for j in range(num_predictions):\n",
    "        smape_row.append(smape_clean(predictions.iloc[i, j], df_test.iloc[i, j]))\n",
    "    smapes.loc[i] = smape_row\n",
    "\n",
    "print(smapes)\n",
    "\n",
    "smape_avgs = []\n",
    "for i in range(num_predictions):\n",
    "    smape_avgs.append(np.mean(smapes.iloc[:,i]))\n",
    "print(smape_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = []\n",
    "# y_hat = []\n",
    "# details = []\n",
    "# offset = 7\n",
    "# for i in range(0,10):\n",
    "#     y.append(observations[i+offset][1])\n",
    "#     y_hat.append(y[i] + 0.4)\n",
    "#     details.append(observations[i+offset])\n",
    "\n",
    "# repY = []\n",
    "# repY_hat = []\n",
    "# smape = 0\n",
    "# for i in range(10):\n",
    "#     repY.append(reprocess(y[i], details[i]))\n",
    "#     repY_hat.append(reprocess(y_hat[i], details[i]))\n",
    "#     smape += smape_clean(repY[i], repY_hat[i])\n",
    "\n",
    "# smape /= len(repY)\n",
    "# print(smape)\n",
    "# pyplot.plot(repY, label='original')\n",
    "# pyplot.plot(repY_hat, label='altered')\n",
    "# pyplot.plot(df_train.iloc[1,3:10], label = 'og')\n",
    "# pyplot.legend()\n",
    "# pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38918c03f5e50da0883dd5b0b10b29c968b274fb52fc312fcc1e11a6fe51f463"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
