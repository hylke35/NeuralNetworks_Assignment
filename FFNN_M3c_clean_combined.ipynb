{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import seaborn\n",
    "import numpy as np\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fixed-window sequences for training and validation data\n",
    "def create_sequences(X, window_size):\n",
    "    seq_X = []\n",
    "    seq_y = []\n",
    "    for i in range(len(X) - window_size):\n",
    "        seq_X.append(X[i:i+window_size])\n",
    "        seq_y.append(X[i+window_size])\n",
    "    return seq_X, seq_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reprocess(y, details):\n",
    "    # print(details)\n",
    "    mean = details[2][0]\n",
    "    std = details[2][1]\n",
    "    PF = details[2][2]\n",
    "    PFtype = details[2][3]\n",
    "    time = details[3]\n",
    "\n",
    "    # print(\"mean:\", mean, \"std:\", std, \"PF\", PF, \"type\", PFtype, \"time\", time)\n",
    "\n",
    "    if(PFtype == 1):\n",
    "        return ((y * std) + mean) * np.exp(PF[0] * time + PF[1])    \n",
    "    # print(\"here\")\n",
    "    return (y * std + mean) * (PF[0] * np.square(time) + PF[1] * time + PF[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    PFtype = -1\n",
    "    PF1 = np.polyfit(np.linspace(0,len(data) - 1,num=len(data)), np.log(data), 1)\n",
    "    PF2 = np.polyfit(np.linspace(0,len(data) - 1,num=len(data)),data, 2)\n",
    "    error1 = data - (np.exp(PF1[0] * np.linspace(0, len(data) - 1, num=len(data)) + PF1[1]))\n",
    "    error2 = data - (PF2[0] * np.square(np.linspace(0,len(data) - 1,num=len(data))) + PF2[1] * np.linspace(0, len(data) - 1, num=len(data)) + PF2[2])\n",
    "    \n",
    "    #Otto: dit is de keuze voro welke je preporcessed. je kan die plotjes un commenten om de fit te zien\n",
    "    if(np.sum(np.square(error1)) < np.sum(np.square(error2))):\n",
    "        PF = PF1\n",
    "        preprocessed = data / (np.exp(PF[0] * np.linspace(0,len(data) - 1,num=len(data)) + PF[1]))\n",
    "        PFtype = 1\n",
    "    else:\n",
    "        PF = PF2\n",
    "        preprocessed = data / (PF2[0] * np.square(np.linspace(0,len(data) - 1,num=len(data))) + PF2[1] * np.linspace(0,len(data) - 1,num=len(data)) + PF2[2])\n",
    "        PFtype = 2\n",
    "    \n",
    "    m = np.mean(preprocessed)\n",
    "    s = np.std(preprocessed)\n",
    "    preprocessed = (preprocessed - m)/s\n",
    "    details = [m, s, PF, PFtype]\n",
    "    \n",
    "    return preprocessed, details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess2(data):\n",
    "\n",
    "    PF = np.polyfit(np.linspace(0,len(data),num=len(data)), np.log(data), 1)\n",
    "\n",
    "    preprocessed = data / (np.exp(PF[0] * np.linspace(0,len(data),num=len(data)) + PF[1]))\n",
    "    m = np.mean(preprocessed)\n",
    "    s = np.std(preprocessed)\n",
    "    preprocessed = (preprocessed - m)/s\n",
    "\n",
    "    details = [m, s, PF]\n",
    "\n",
    "    return preprocessed, details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_clean(y_true, y_pred):\n",
    "    smape = 100 * np.mean(2*np.abs(y_pred - y_true) / (y_true + y_pred))\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(model, validation):\n",
    "    validation_x = []\n",
    "    validation_y = []\n",
    "    for val in validation:\n",
    "        validation_x.append(val[0])\n",
    "        validation_y.append(val[1])\n",
    "    validation_x = np.array(validation_x)\n",
    "    validation_y = np.array(validation_y)\n",
    "    smape = 0\n",
    "    prediction = model.predict(validation_x, verbose=0)\n",
    "    # _, acc = model.evaluate(validation_x, validation_y, verbose = 0)\n",
    "\n",
    "    # print(\"sse val is; \", np.sum(np.square(validation_y - prediction))/len(validation_y), \"val is \", acc)\n",
    "    for i in range(len(validation)):\n",
    "        observation = validation[i]\n",
    "        pred = prediction[i]\n",
    "        #print(pred, observation[1], pred - observation[1])\n",
    "        x_hat = reprocess(pred, observation)\n",
    "        x = reprocess(observation[1], observation)\n",
    "        #print(x_hat, x, x_hat - x)\n",
    "\n",
    "        smape += 2*np.abs(x_hat-x)/(x+x_hat)\n",
    "\n",
    "    smape /= len(validation)\n",
    "    smape *=100\n",
    "\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(x_train, y_train, x_validation, y_validation, window_size, options): #x_validation, y_validation\n",
    "    # Build the FFNN model\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(window_size, 1))) \n",
    "    model.add(keras.layers.Dense(options.layers[0], activation='sigmoid'))\n",
    "\n",
    "    if len(options.layers) > 2:\n",
    "        for i in range(1,len(options.layers)-1):\n",
    "            model.add(keras.layers.Dense(options.layers[i], activation=options.activation))\n",
    "                \n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "    #early stopping and saving the best model SOURCE: https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=50, min_delta=0.001)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=0, save_best_only=True)\n",
    "    # fit model\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(x_train, y_train, validation_data=(x_validation, y_validation), batch_size=options.batchSize, verbose = 0, callbacks=[es, mc], epochs= 1000) #fit the model with early stop\n",
    "\n",
    "    ##this is the best model\n",
    "    saved_model = load_model(\"best_model.h5\")\n",
    "\n",
    "    _, train_acc = saved_model.evaluate(x_train, y_train, verbose = 0)\n",
    "    _, test_acc = saved_model.evaluate(x_validation, y_validation, verbose = 0)\n",
    "\n",
    "    print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "\n",
    "    # plot the different accuracies. maybe then dont do a early stop. \n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='validation')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "\n",
    "    return saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"M3C.xls\")\n",
    "df = df.iloc[:146,6:26]\n",
    "\n",
    "df_train = df.iloc[:,:14]\n",
    "df_test = df.iloc[:,14:]\n",
    "\n",
    "window_size = 3\n",
    "\n",
    "observations = []\n",
    "details = []\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    preprocessed, detail = preprocess(np.array(row))\n",
    "    details.append(detail)\n",
    "    for i in range(len(preprocessed) - window_size):\n",
    "        observations.append([preprocessed[i:i+window_size],preprocessed[i+window_size], detail, i+window_size])\n",
    "\n",
    "train = observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [6,10,13]\n",
    "def kfolds(df_train, folds):\n",
    "    for fold in folds:\n",
    "        train = df_train.iloc[:,:fold]\n",
    "        validate = df_train.iloc[:,fold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling: dont use for now\n",
    "\n",
    "# np.random.shuffle(observations)\n",
    "# train = observations[:int(np.floor(len(observations)*0.8))]\n",
    "# validation = observations[int(np.floor(len(observations)*0.8)):]\n",
    "\n",
    "def kfolds(observations, folds, options):\n",
    "    avgSmape = []\n",
    "    for fold in folds:\n",
    "        validationSet = []\n",
    "        x_train = []\n",
    "        y_train = []\n",
    "        for i in range(0, len(observations), (14 - window_size)):\n",
    "            validationSet.append(observations[fold + i])\n",
    "            #print(\"appended to validation set obseravtion\", observations[fold + i])\n",
    "            #print(\"appended to train set observation \", end=\"\")\n",
    "            for j in range(fold):\n",
    "                #print(observations[j + i][0], observations[j + i][1] )\n",
    "                x_train.append(observations[j + i][0])\n",
    "                y_train.append(observations[j + i][1])\n",
    "            #print()\n",
    "        x_train = np.array(x_train)\n",
    "        y_train = np.array(y_train)\n",
    "        #otto: we should shuffel here (maby make df first, shuffel and then tear it appart again, y and x should stay together)\n",
    "\n",
    "        ##extract validation info for early stop. \n",
    "        x_validation = []\n",
    "        y_validation = []\n",
    "        for valObs in validationSet:\n",
    "            x_validation.append(valObs[0])\n",
    "            y_validation.append(valObs[1])\n",
    "        x_validation = np.array(x_validation)\n",
    "        y_validation = np.array(y_validation)\n",
    "        #print(validationSet[0])\n",
    "\n",
    "        model = build_model(x_train, y_train, x_validation, y_validation, window_size, options)\n",
    "        #now estimate with the model on the validation set\n",
    "        validationPredicition = model.predict(x_validation, verbose=0)\n",
    "        yHatReal = []\n",
    "        yReal = []\n",
    "        for i in range(len(validationSet)):\n",
    "            yReal.append(reprocess(y_validation[i], validationSet[i]))\n",
    "            yHatReal.append(reprocess(validationPredicition[i], validationSet[i]) )\n",
    "        smapeVal = 0\n",
    "        for i in range(len(yReal)):\n",
    "            smapeVal += smape_clean(yReal[i], yHatReal[i])\n",
    "        smapeVal /= len(yReal)\n",
    "        print(\"smape equals\", smapeVal, \"with\", fold, \"time step as training\")\n",
    "        avgSmape.append(smapeVal)\n",
    "    return np.mean(avgSmape), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    print(i, train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lays = [[10], [2,2], [3,2], [4,4,4], [10,10,10]]\n",
    "epochs = [50]\n",
    "batchSizes = [16]\n",
    "activationFunctions = ['relu']\n",
    "\n",
    "options = []\n",
    "\n",
    "for layer in lays:\n",
    "    for activation in activationFunctions:\n",
    "        for batchSize in batchSizes:\n",
    "                options.append([layer, activation, batchSize, 0, 0])\n",
    "\n",
    "\n",
    "options = pd.DataFrame(options)\n",
    "options = options.set_axis(['layers', 'activation', 'batchSize', 'averageSmape', 'varianceSmape'], axis=1)\n",
    "\n",
    "# print(options.iloc[0].layers)\n",
    "\n",
    "for i in range(len(options)):\n",
    "    smape_avg=[]\n",
    "    for j in range(1):\n",
    "        smp, model = kfolds(train, [1,2,3,4,5,6,7,8,9,10], options.iloc[i])\n",
    "        smape_avg.append(smp)\n",
    "\n",
    "    options.iat[i,3] = np.mean(smape_avg)\n",
    "    options.iat[i,4] = np.std(smape_avg)\n",
    "\n",
    "\n",
    "op = pd.DataFrame(options)\n",
    "res = op.sort_values(by=\"averageSmape\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(op.sort_values(by=\"averageSmape\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TESTING\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "observations = []\n",
    "window_size = 3\n",
    "\n",
    "df_full = pd.DataFrame()\n",
    "df_full = df_train\n",
    "df_full = df_full.drop(df_full.columns[14:], axis=1)\n",
    "\n",
    "num_predictions = 6\n",
    "\n",
    "# Make predictions using autoregressive approach\n",
    "for pred in range(num_predictions):\n",
    "\n",
    "    PF = []\n",
    "    for index, row in df_full.iterrows():\n",
    "        preprocessed, details = preprocess(np.array(row))\n",
    "        PF.append(details[2:])\n",
    "        observations.append([preprocessed[11+pred:14+pred],0, details, 14+pred]) #y is unknown and first time point to predict is 15(or 14?)`\n",
    "\n",
    "    # Reshape the input for prediction\n",
    "    x = []\n",
    "    for i in (range(len(observations))):\n",
    "        x.append(observations[i][0])\n",
    "    x = np.array(x).reshape(len(x),window_size)\n",
    "    \n",
    "    # Make the prediction\n",
    "    prediction = model.predict(x)\n",
    "\n",
    "    y_u = []\n",
    "    for i in range(len(prediction)):\n",
    "        y_u.append(reprocess(prediction[i], observations[i]))\n",
    "\n",
    "    # print(pd.DataFrame(y_u).shape)\n",
    "    predictions[15+pred] = pd.DataFrame(pd.DataFrame(y_u))\n",
    "    df_full[15+pred] = pd.DataFrame(y_u)\n",
    "\n",
    "smapes = pd.DataFrame(columns=[i for i in range(num_predictions)])\n",
    "\n",
    "for i in range(predictions.shape[0]):\n",
    "    smape_row = []\n",
    "    for j in range(num_predictions):\n",
    "        smape_row.append(smape_clean(predictions.iloc[i, j], df_test.iloc[i, j]))\n",
    "    smapes.loc[i] = smape_row\n",
    "\n",
    "print(smapes)\n",
    "\n",
    "smape_avgs = []\n",
    "for i in range(num_predictions):\n",
    "    smape_avgs.append(np.mean(smapes.iloc[:,i]))\n",
    "print(smape_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = []\n",
    "# y_hat = []\n",
    "# details = []\n",
    "# offset = 7\n",
    "# for i in range(0,10):\n",
    "#     y.append(observations[i+offset][1])\n",
    "#     y_hat.append(y[i] + 0.4)\n",
    "#     details.append(observations[i+offset])\n",
    "\n",
    "# repY = []\n",
    "# repY_hat = []\n",
    "# smape = 0\n",
    "# for i in range(10):\n",
    "#     repY.append(reprocess(y[i], details[i]))\n",
    "#     repY_hat.append(reprocess(y_hat[i], details[i]))\n",
    "#     smape += smape_clean(repY[i], repY_hat[i])\n",
    "\n",
    "# smape /= len(repY)\n",
    "# print(smape)\n",
    "# pyplot.plot(repY, label='original')\n",
    "# pyplot.plot(repY_hat, label='altered')\n",
    "# pyplot.plot(df_train.iloc[1,3:10], label = 'og')\n",
    "# pyplot.legend()\n",
    "# pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
