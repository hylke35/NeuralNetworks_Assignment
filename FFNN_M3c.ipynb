{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import seaborn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fixed-window sequences for training and validation data\n",
    "def create_sequences(X, window_size):\n",
    "    seq_X = []\n",
    "    seq_y = []\n",
    "    for i in range(len(X) - window_size):\n",
    "        seq_X.append(X[i:i+window_size])\n",
    "        seq_y.append(X[i+window_size])\n",
    "    return seq_X, seq_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "\n",
    "    PF = np.polyfit(np.linspace(0,len(data),num=len(data)), np.log(data), 1)\n",
    "\n",
    "    preprocessed = data / (np.exp(PF[0] * np.linspace(0,len(data),num=len(data)) + PF[1]))\n",
    "    m = np.mean(preprocessed)\n",
    "    s = np.std(preprocessed)\n",
    "    preprocessed = (preprocessed - m)/s\n",
    "\n",
    "    details = [m, s, PF]\n",
    "\n",
    "    return preprocessed, details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reprocess(y, details):\n",
    "    mean = details[2][0]\n",
    "    std = details[2][1]\n",
    "    PF = details[2][2]\n",
    "    time = details[3]\n",
    "    \n",
    "    return ((y * std) + mean) * np.exp(PF[0] * time + PF[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_loss(y_true, y_pred):\n",
    "    smape = 100 * tf.reduce_mean(2*tf.abs(y_pred - y_true) / (y_true + y_pred))\n",
    "    return smape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(model, validation):\n",
    "    smape = 0\n",
    "    prediction = model.predict(x_validation)\n",
    "    for i in range(len(validation)):\n",
    "        observation = validation[i]\n",
    "        pred = prediction[i]\n",
    "\n",
    "        x_hat = reprocess(pred, observation)\n",
    "        x = reprocess(observation[1], observation)\n",
    "\n",
    "        smape += 2*np.abs(x_hat-x)/(x+x_hat)\n",
    "\n",
    "    smape /= len(validation)\n",
    "    smape *=100\n",
    "\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(x_train, y_train, x_validation, y_validation, window_size, options):\n",
    "    # Build the FFNN model\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(window_size, 1))) \n",
    "    model.add(keras.layers.Dense(options[0][0], activation='relu'))\n",
    "\n",
    "    if len(options[0]) > 1:\n",
    "        if len(options[0]) > 2:\n",
    "            for i in range(1,len(options[0])-1):\n",
    "                model.add(keras.layers.Dense(options[0][i], activation=options[1]))\n",
    "                \n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "    # Train the model\n",
    "    # model.fit(x_train, y_train, epochs=options[3], batch_size=options[2], validation_data=(x_validation, y_validation), verbose = 0)\n",
    "    model.fit(x_train, y_train, epochs=options[3], batch_size=options[2], verbose = 0)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(x_validation)\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(x_validation, y_validation)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"/Users/lars/Documents/GitHub/NeuralNetworks_Assignment/M3C.xls\")\n",
    "df = df.iloc[:146,6:26]\n",
    "\n",
    "df_train = df.iloc[:,:14]\n",
    "df_test = df.iloc[:,14:]\n",
    "\n",
    "window_size = 3\n",
    "\n",
    "observations = []\n",
    "PF = []\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    preprocessed, p = preprocess(np.array(row))\n",
    "    PF.append(p)\n",
    "   \n",
    "    for i in range(len(preprocessed) - window_size):\n",
    "        observations.append([preprocessed[i:i+window_size],preprocessed[i+window_size], p, i+window_size])     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling: dont use for now\n",
    "# np.random.shuffle(observations)\n",
    "\n",
    "train = observations[:int(np.floor(len(observations)*0.8))]\n",
    "validation = observations[int(np.floor(len(observations)*0.8)):]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_validation = []\n",
    "y_validation = []\n",
    "\n",
    "folds = [6,10,13]\n",
    "\n",
    "\n",
    "for i in range(len(train)):\n",
    "    x_train.append(train[i][0])\n",
    "    y_train.append(train[i][1])\n",
    "\n",
    "for i in range(len(validation)):\n",
    "    x_validation.append(validation[i][0])\n",
    "    y_validation.append(validation[i][1])\n",
    "\n",
    "x_train = np.array(x_train).reshape(len(x_train),window_size)\n",
    "y_train = np.array(y_train).reshape(len(y_train))\n",
    "x_validation = np.array(x_validation).reshape(len(x_validation),window_size)\n",
    "y_validation = np.array(y_validation).reshape(len(x_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 475us/step\n",
      "11/11 [==============================] - 0s 568us/step - loss: 0.9472 - mse: 0.9472\n",
      "[[50, 50], 'sigmoid', 16, 50, 0, 0]\n",
      "11/11 [==============================] - 0s 482us/step\n",
      "          0        1   2   3          4    5\n",
      "0  [50, 50]  sigmoid  16  50  14.711936  0.0\n"
     ]
    }
   ],
   "source": [
    "lays = [[50,50]]\n",
    "epochs = [50]\n",
    "batchSizes = [16]\n",
    "activationFunctions = ['sigmoid']\n",
    "\n",
    "options = []\n",
    "\n",
    "for layer in lays:\n",
    "    for activation in activationFunctions:\n",
    "        for batchSize in batchSizes:\n",
    "            for epoch in epochs:\n",
    "                options.append([layer, activation, batchSize, epoch, 0, 0])\n",
    "\n",
    "\n",
    "for i in range(len(options)):\n",
    "    smape_avg=[]\n",
    "    for j in range(1):\n",
    "        model = build_model(x_train, y_train, x_validation, y_validation, window_size, options[i])\n",
    "\n",
    "        print(options[i])\n",
    "        \n",
    "        smape_avg.append(smape(model, validation))\n",
    "\n",
    "    options[i][4] = np.mean(smape_avg)\n",
    "    options[i][5] = np.std(smape_avg)\n",
    "\n",
    "\n",
    "op = pd.DataFrame(options)\n",
    "res = op.sort_values(4, ascending=False)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 459us/step\n",
      "11/11 [==============================] - 0s 576us/step - loss: 0.9468 - mse: 0.9468\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for the final model build we should do something better but i focussed on the autoregression for now\n",
    "lays = [[50,50]]\n",
    "epochs = [50]\n",
    "batchSizes = [16]\n",
    "activationFunctions = ['sigmoid']\n",
    "\n",
    "options = [layer, activation, batchSize, epoch, 0, 0]\n",
    "\n",
    "model = build_model(x_train, y_train, x_validation, y_validation, window_size, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_clean(y_true, y_pred):\n",
    "    smape = 100 * np.mean(2*np.abs(y_pred - y_true) / (y_true + y_pred))\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 693us/step\n",
      "10/10 [==============================] - 0s 554us/step\n",
      "14/14 [==============================] - 0s 470us/step\n",
      "19/19 [==============================] - 0s 449us/step\n",
      "23/23 [==============================] - 0s 425us/step\n",
      "28/28 [==============================] - 0s 401us/step\n",
      "             0          1          2          3          4          5\n",
      "0     4.457461  17.931971  28.804478  41.651366  48.146654  56.090897\n",
      "1    20.387434   4.864991  14.915162  15.092009  14.871977  12.113167\n",
      "2    51.642259  36.462417  41.792754  39.204962  40.942536  53.578291\n",
      "3    25.127843  13.642950   5.790956  16.566503  10.364864  17.895001\n",
      "4    10.462952  17.361462  29.811762  37.052851  29.687283  18.990138\n",
      "..         ...        ...        ...        ...        ...        ...\n",
      "141   7.437902   0.188281   4.260280   6.702316   1.424700   0.129322\n",
      "142   9.995316   4.414887  15.593822   7.235593   9.131973   3.482213\n",
      "143   1.744891  13.655668  16.060816  15.794610  32.966773  49.663972\n",
      "144  30.191374  39.676759  47.967080  59.600854  73.862974  95.156653\n",
      "145  35.521796  35.648353  18.157387  10.900166  33.936527  49.413984\n",
      "\n",
      "[146 rows x 6 columns]\n",
      "[16.40121573649749, 19.930942326354174, 28.61359902194544, 28.015883396845062, 32.99716355842322, 36.421480662787474]\n"
     ]
    }
   ],
   "source": [
    "##TESTING\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "observations = []\n",
    "window_size = 3\n",
    "\n",
    "df_full = pd.DataFrame()\n",
    "df_full = df_train\n",
    "df_full = df_full.drop(df_full.columns[14:], axis=1)\n",
    "\n",
    "num_predictions = 6\n",
    "\n",
    "# Make predictions using autoregressive approach\n",
    "for pred in range(num_predictions):\n",
    "\n",
    "    PF = []\n",
    "    for index, row in df_full.iterrows():\n",
    "        preprocessed, p = preprocess(np.array(row))\n",
    "        PF.append(p)\n",
    "        observations.append([preprocessed[11+pred:14+pred],0, p, 14+pred]) #y is unknown and first time point to predict is 15(or 14?)`\n",
    "\n",
    "    # Reshape the input for prediction\n",
    "    x = []\n",
    "    for i in (range(len(observations))):\n",
    "        x.append(observations[i][0])\n",
    "    x = np.array(x).reshape(len(x),window_size)\n",
    "    \n",
    "    # Make the prediction\n",
    "    prediction = model.predict(x)\n",
    "\n",
    "    y_u = []\n",
    "    for i in range(len(prediction)):\n",
    "        y_u.append(reprocess(prediction[i], observations[i]))\n",
    "\n",
    "    # print(pd.DataFrame(y_u).shape)\n",
    "    predictions[15+pred] = pd.DataFrame(pd.DataFrame(y_u))\n",
    "    df_full[15+pred] = pd.DataFrame(y_u)\n",
    "\n",
    "smapes = pd.DataFrame(columns=[i for i in range(num_predictions)])\n",
    "\n",
    "for i in range(predictions.shape[0]):\n",
    "    smape_row = []\n",
    "    for j in range(num_predictions):\n",
    "        smape_row.append(smape_clean(predictions.iloc[i, j], df_test.iloc[i, j]))\n",
    "    smapes.loc[i] = smape_row\n",
    "\n",
    "print(smapes)\n",
    "\n",
    "smape_avgs = []\n",
    "for i in range(num_predictions):\n",
    "    smape_avgs.append(np.mean(smapes.iloc[:,i]))\n",
    "print(smape_avgs)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38918c03f5e50da0883dd5b0b10b29c968b274fb52fc312fcc1e11a6fe51f463"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
