{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import seaborn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fixed-window sequences for training and validation data\n",
    "def create_sequences(X, window_size):\n",
    "    seq_X = []\n",
    "    seq_y = []\n",
    "    for i in range(len(X) - window_size):\n",
    "        seq_X.append(X[i:i+window_size])\n",
    "        seq_y.append(X[i+window_size])\n",
    "    return seq_X, seq_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "\n",
    "    PF = np.polyfit(np.linspace(0,len(data),num=len(data)), np.log(data), 1)\n",
    "\n",
    "    preprocessed = data / (np.exp(PF[0] * np.linspace(0,len(data),num=len(data)) + PF[1]))\n",
    "    m = np.mean(preprocessed)\n",
    "    s = np.std(preprocessed)\n",
    "    preprocessed = (preprocessed - m)/s\n",
    "\n",
    "    details = [m, s, PF]\n",
    "\n",
    "    return preprocessed, details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reprocess(y, details):\n",
    "    mean = details[2][0]\n",
    "    std = details[2][1]\n",
    "    PF = details[2][2]\n",
    "    time = details[3]\n",
    "    \n",
    "    return ((y * std) + mean) * np.exp(PF[0] * time + PF[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_loss(y_true, y_pred):\n",
    "    smape = 100 * tf.reduce_mean(2*tf.abs(y_pred - y_true) / (y_true + y_pred))\n",
    "    return smape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(model, validation):\n",
    "    smape = 0\n",
    "    prediction = model.predict(x_validation)\n",
    "    for i in range(len(validation)):\n",
    "        observation = validation[i]\n",
    "        pred = prediction[i]\n",
    "\n",
    "        x_hat = reprocess(pred, observation)\n",
    "        x = reprocess(observation[1], observation)\n",
    "\n",
    "        smape += 2*np.abs(x_hat-x)/(x+x_hat)\n",
    "\n",
    "    smape /= len(validation)\n",
    "    smape *=100\n",
    "\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(x_train, y_train, x_validation, y_validation, window_size, options):\n",
    "    # Build the FFNN model\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(window_size, 1))) \n",
    "    model.add(keras.layers.Dense(options[0][0], activation='relu'))\n",
    "\n",
    "    if len(options[0]) > 1:\n",
    "        if len(options[0]) > 2:\n",
    "            for i in range(1,len(options[0])-1):\n",
    "                model.add(keras.layers.Dense(options[0][i], activation=options[1]))\n",
    "                \n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "    # Train the model\n",
    "    # model.fit(x_train, y_train, epochs=options[3], batch_size=options[2], validation_data=(x_validation, y_validation), verbose = 0)\n",
    "    model.fit(x_train, y_train, epochs=options[3], batch_size=options[2], verbose = 0)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(x_validation)\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(x_validation, y_validation)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"/Users/lars/Documents/GitHub/NeuralNetworks_Assignment/M3C.xls\")\n",
    "df = df.iloc[:146,6:26]\n",
    "\n",
    "df_train = df.iloc[:,:14]\n",
    "df_test = df.iloc[:,14:]\n",
    "\n",
    "window_size = 3\n",
    "\n",
    "observations = []\n",
    "PF = []\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    preprocessed, p = preprocess(np.array(row))\n",
    "    PF.append(p)\n",
    "   \n",
    "    for i in range(len(preprocessed) - window_size):\n",
    "        observations.append([preprocessed[i:i+window_size],preprocessed[i+window_size], p, i+window_size])     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling: dont use for now\n",
    "# np.random.shuffle(observations)\n",
    "\n",
    "train = observations[:int(np.floor(len(observations)*0.8))]\n",
    "validation = observations[int(np.floor(len(observations)*0.8)):]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_validation = []\n",
    "y_validation = []\n",
    "\n",
    "folds = [6,10,13]\n",
    "\n",
    "\n",
    "for i in range(len(train)):\n",
    "    x_train.append(train[i][0])\n",
    "    y_train.append(train[i][1])\n",
    "\n",
    "for i in range(len(validation)):\n",
    "    x_validation.append(validation[i][0])\n",
    "    y_validation.append(validation[i][1])\n",
    "\n",
    "x_train = np.array(x_train).reshape(len(x_train),window_size)\n",
    "y_train = np.array(y_train).reshape(len(y_train))\n",
    "x_validation = np.array(x_validation).reshape(len(x_validation),window_size)\n",
    "y_validation = np.array(y_validation).reshape(len(x_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 676us/step\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.9468 - mse: 0.9468\n",
      "[[50, 50], 'sigmoid', 16, 50, 0, 0]\n",
      "11/11 [==============================] - 0s 485us/step\n",
      "          0        1   2   3          4    5\n",
      "0  [50, 50]  sigmoid  16  50  14.769352  0.0\n"
     ]
    }
   ],
   "source": [
    "lays = [[50,50]]\n",
    "epochs = [50]\n",
    "batchSizes = [16]\n",
    "activationFunctions = ['sigmoid']\n",
    "\n",
    "options = []\n",
    "\n",
    "for layer in lays:\n",
    "    for activation in activationFunctions:\n",
    "        for batchSize in batchSizes:\n",
    "            for epoch in epochs:\n",
    "                options.append([layer, activation, batchSize, epoch, 0, 0])\n",
    "\n",
    "\n",
    "for i in range(len(options)):\n",
    "    smape_avg=[]\n",
    "    for j in range(1):\n",
    "        model = build_model(x_train, y_train, x_validation, y_validation, window_size, options[i])\n",
    "\n",
    "        print(options[i])\n",
    "        \n",
    "        smape_avg.append(smape(model, validation))\n",
    "\n",
    "    options[i][4] = np.mean(smape_avg)\n",
    "    options[i][5] = np.std(smape_avg)\n",
    "\n",
    "\n",
    "op = pd.DataFrame(options)\n",
    "res = op.sort_values(4, ascending=False)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 728us/step\n",
      "11/11 [==============================] - 0s 616us/step - loss: 0.9461 - mse: 0.9461\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for the final model build we should do something better but i focussed on the autoregression for now\n",
    "lays = [[50,50]]\n",
    "epochs = [50]\n",
    "batchSizes = [16]\n",
    "activationFunctions = ['sigmoid']\n",
    "\n",
    "options = [layer, activation, batchSize, epoch, 0, 0]\n",
    "\n",
    "model = build_model(x_train, y_train, x_validation, y_validation, window_size, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_clean(y_true, y_pred):\n",
    "    smape = 100 * np.mean(2*np.abs(y_pred - y_true) / (y_true + y_pred))\n",
    "    return smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 850us/step\n",
      "10/10 [==============================] - 0s 631us/step\n",
      "14/14 [==============================] - 0s 572us/step\n",
      "19/19 [==============================] - 0s 458us/step\n",
      "23/23 [==============================] - 0s 531us/step\n",
      "28/28 [==============================] - 0s 481us/step\n",
      "             0          1          2          3          4          5\n",
      "0     4.449873  17.924441  28.797043  41.644103  48.139502  56.083903\n",
      "1    20.389036   4.866609  14.916772  15.093619  14.873587  12.114780\n",
      "2    51.645111  36.465372  41.795677  39.207901  40.945464  53.581129\n",
      "3    25.159627  13.675094   5.823222  16.598575  10.397071  17.927036\n",
      "4    10.492119  17.390489  29.840359  37.081094  29.715886  19.019121\n",
      "..         ...        ...        ...        ...        ...        ...\n",
      "141   7.772731   0.147033   4.595429   7.037235   1.759993   0.205992\n",
      "142   9.995316   4.414887  15.593822   7.235593   9.131973   3.482213\n",
      "143   1.560361  13.471975  16.244155  15.611205  32.787217  49.490770\n",
      "144  30.193228  39.678582  47.968869  59.602583  73.864613  95.158121\n",
      "145  35.236332  35.362955  17.865092  10.606333  34.222655  49.690580\n",
      "\n",
      "[146 rows x 6 columns]\n",
      "[16.420875872453376, 19.958003562088262, 28.65288754838708, 27.999081897693486, 32.99702172637838, 36.45023479390531]\n"
     ]
    }
   ],
   "source": [
    "##TESTING\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "observations = []\n",
    "window_size = 3\n",
    "\n",
    "df_full = pd.DataFrame()\n",
    "df_full = df_train\n",
    "df_full = df_full.drop(df_full.columns[14:], axis=1)\n",
    "\n",
    "num_predictions = 6\n",
    "\n",
    "# Make predictions using autoregressive approach\n",
    "for pred in range(num_predictions):\n",
    "\n",
    "    PF = []\n",
    "    for index, row in df_full.iterrows():\n",
    "        preprocessed, p = preprocess(np.array(row))\n",
    "        PF.append(p)\n",
    "        observations.append([preprocessed[11+pred:14+pred],0, p, 14+pred]) #y is unknown and first time point to predict is 15(or 14?)`\n",
    "\n",
    "    # Reshape the input for prediction\n",
    "    x = []\n",
    "    for i in (range(len(observations))):\n",
    "        x.append(observations[i][0])\n",
    "    x = np.array(x).reshape(len(x),window_size)\n",
    "    \n",
    "    # Make the prediction\n",
    "    prediction = model.predict(x)\n",
    "\n",
    "    y_u = []\n",
    "    for i in range(len(prediction)):\n",
    "        y_u.append(reprocess(prediction[i], observations[i]))\n",
    "\n",
    "    # print(pd.DataFrame(y_u).shape)\n",
    "    predictions[15+pred] = pd.DataFrame(pd.DataFrame(y_u))\n",
    "    df_full[15+pred] = pd.DataFrame(y_u)\n",
    "\n",
    "smapes = pd.DataFrame(columns=[i for i in range(num_predictions)])\n",
    "\n",
    "for i in range(predictions.shape[0]):\n",
    "    smape_row = []\n",
    "    for j in range(num_predictions):\n",
    "        smape_row.append(smape_clean(predictions.iloc[i, j], df_test.iloc[i, j]))\n",
    "    smapes.loc[i] = smape_row\n",
    "\n",
    "print(smapes)\n",
    "\n",
    "smape_avgs = []\n",
    "for i in range(num_predictions):\n",
    "    smape_avgs.append(np.mean(smapes.iloc[:,i]))\n",
    "print(smape_avgs)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38918c03f5e50da0883dd5b0b10b29c968b274fb52fc312fcc1e11a6fe51f463"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
